\chapter{MDopt}

Una de las razones por las que decidí estudiar matemáticas aplicadas es justamente por la parte de 'aplicadas'. Cuando en los cursos de estadística comencé a aprender sobre modelos que pueden describir información real, mi sorpresa y emoción fueron auténticas. Sin embargo, en esas clases también aprendí que hay muchos modelos posibles para un conjunto de datos y no hay una sola manera de elegir el \textit{mejor} modelo. Por lo tanto, para darle continuidad al tema de modelos lineales decidí abordar el problema de discriminación de modelos usando el método con el criterio MD, \textit{Model Discrimination} propuesto por Box y Hill. 

En primer lugar, hay que discriminar entre las variables o factores que realmente afectan la variable de respuesta de las que no. Para esto se puede utilizar el método bayesiano descrito por Ana Patricia Vela \cite{tesis_paty}. Hay ocasiones donde utilizando este método es muy fácil determinar si un factor afecta o no la variable de respuesta. Sin embargo, hay ocasiones donde los resultados son ambiguos y pareciera que hay varios modelos que describen los datos. Por lo tanto, la estrategia que se usa es agregar ensayos adicionales específicos que, una vez agregados a los ensayos originales, darán una idea más clara sobre cuál es el mejor modelo. 

Uno de estos métodos es el  que utiliza el criterio MD, de \textit{Model Discrimination}. La idea de este criterio es elegir ensayos que permitan la máxima discriminación posible entre los modelos probables \cite{meyer1996}. 

En primer lugar, expongo un resumen del método completo descrito por \cite{meyer1996} para la discriminación de modelos. Posteriormente, expongo la explicación detallada y matemática del criterio MD y el algoritmo de intercambio. Finalmente, hago la comparación entre los tres lenguajes con dos ejemplos. 

\section{Metodología completa}

El proceso de identificación de los factores activos de un modelo no es sencillo ya que incluye pasos que usan estadística bayesiana. La explicación detallada está fuera del alcance de este trabajo, pero se puede encontrar en \cite{meyer1996}. Sin embargo, daré un breve resumen para tener el contexto donde se usan el criterio MD y el algoritmo de intercambio. Los detalles matemáticos están explicados en las siguientes secciones. 

Supongamos que voy a realizar un experimento. Para esto, tengo que hacer un diseño con los factores que voy a incluir, sus niveles y los ensayos que voy a hacer. Como experta en el experimento debo tener una idea de cuáles modelos son los más probables a describir el experimento. Este conocimiento a priori se le denomina $P(M_i)$. 

Después, ya que realicé el experimento tengo los niveles que use para cada factor y la respuesta obtenida $Y$. Con esta nueva información puedo calcular la probabilidad de que cada modelo $M_i$ sea el correcto. Es decir, calculo $P(M_i | Y)$. Además, puedo calcular $P_j$, la probabilidad de que el factor $j$ esté activo. Las probabilidades más altas me indican cuáles son los posibles factores activos. 

Si hay una clara diferencia entre las probabilidades $P_j$ de los factores entonces puedo separar los activos de los no activos. En cambio, si no hay una clara diferencia entre probabilidades $P_j$ \cite{Meyer} explica que se deben hacer más ensayos para discriminar entre los posibles modelos. 

En la elección de esos ensayos es donde entra el criterio MD ya que es un número que indica cuales ensayos vale la pena repetir para obtener la mayor diferencia en el vector respuesta $Y$. Entre mayor sea la diferencia en $Y$, más fácil se puede discriminar entre modelos. El algoritmo de intercambio se usa para calcular el criterio MD para todos las posibles combinaciones de ensayos de forma efectiva. El diagrama \ref{diagrama_completo} muestra la explicación anterior. 

\begin{figure}[h]
	\begin{center}
		\includegraphics[scale=0.5]{Imagenes/diagrama_completo.PNG}
		\caption{Diagrama de metodología descrita por \cite{meyer1996}}
		\label{diagrama_completo}
	\end{center}
\end{figure} 



\section{Criterio MD}
Lo siguiente es la explicación matemática que viene en el artículo de \cite{meyer1996}. 

Supongamos que tenemos un experimento factorial fraccionario con $k$ factores. Sea \textbf{$Y$} el vector de respuestas de tamaño $n \times 1$. El modelo que mejor describe a \textbf{$Y$} depende de cuales factores están activos además de que el análisis debe considerar todas las posibles combinaciones de dichos factores. 

Sea $M_i$ el modelo con una combinación particular de factores activos $f_i$ donde $0 \leq f_i \leq k$. Condicionado a que $M_i$ sea el modelo verdadero, asumimos un modelo lineal normal usual $\textbf{$Y$} \sim N(X_i \beta_i, \sigma^2 I).$ La matriz $X_i$ es la matriz de regresión para $M_i$ e incluye los efectos principales para cada factor activo y sus interacciones hasta cualquier orden deseado. Sea $t_i$ el número de efectos (sin incluir el término constante) en $M_i$. Denotemos a $M_0$ como el modelo sin factores activos. 

Ahora asignaremos distribuciones a priori no informativas al término constante $\beta_0$ y el error la desviación estándar $\sigma$ que serán comunes para todos los modelos. Entonces, $p( \beta_0, \sigma) \propto \dfrac{1}{\sigma}$. El resto de coeficientes $\beta_i$ tienen distribuciones normales a priori con media 0 y desviación estándar $\gamma \sigma$. 

Finalmente, hay que agregar probabilidades a priori a cada uno de los modelos posibles. La regla de Pareto, o \textit{sparsity of effects principle} dice que cuando hay varias variables, el sistema es más probable que esté dominado por los efectos principales e interacciones de orden bajo \cite{montgomery2017design}. En otras palabras, buscamos pocos factores que sean los principales y que la combinación entre ellos sea de orden bajo. Por lo tanto, podemos asumir que existe una probabilidad $\pi, \text{ } 0 < \pi < 1$ que cualquier factor esté activo. Además, asumimos que la creencia a priori de que un factor esté activo es independiente de las creencias de los demás factores. Entonces, la probabilidad a priori del modelo $M_i$ es $P(M_i) = \pi ^f_i (1 - \pi)^{k-f_i}.$ 

Una vez observado el vector de datos \textbf{$Y$}, podemos actualizar las distribuciones de los parámetros para cada modelo y la probabilidad de que cada modelo sea válido. La probabilidad posterior de que $M_i$ sea el modelo correcto es 

\begin{equation*}
	\begin{aligned}
		P(M_i | \textbf{Y}) \propto  \pi ^f_i (1 - \pi)^{k-f_i} \gamma^{-t_i} |\Gamma_i + X_i' X_i |^{-1/2} S_i^{-(n-1)/2}, 		
	\end{aligned}
\end{equation*}

\begin{equation} \label{betai}
	\begin{aligned}
		\hat{\beta_i} = (\Gamma_i + X_i' X_i)^{-1} X_i ' \textbf{Y}, 
	\end{aligned}
\end{equation}

\begin{equation} \label{gamma_i}
	\begin{aligned}
		\Gamma_i = \dfrac{1}{\gamma^{2}} 
		\begin{pmatrix}
			0 & 0 \\
			0 & I_{t_i}
		\end{pmatrix} 
	\end{aligned}
\end{equation}

y 

\begin{equation} \label{delta_i}
	\begin{aligned}
		S_i = (\textbf{Y} - X_i \hat{\beta_i})' (\textbf{Y} - X_i \hat{\beta_i}) + \hat{\beta_i}' \Gamma_i \hat{\beta_i}.
	\end{aligned}
\end{equation}

Es importante notar que las probabilidades $P(M_i | \textbf{Y})$ pueden ser sumadas sobre todos los modelos que inclutyan al factor $j$ para calcular la probabilidad posterior $P_j$ de que el factor $j$ está activo, 

\begin{equation} \label{eq_pj}
	\begin{aligned}
		P_j = \sum_{M_i:factorjactivo} P(M_i | \textbf{Y})
	\end{aligned}
\end{equation}

El conjunto de probabilidades $\{ P_j \}$ da un resumen de la actividad de cada uno de los factores del experimento. 

Si utilizara el análisis bayesiano, el experimento claramente sugeriría un modelo $M_i$ cuando la probabilidad posterior $P(M_i | \textbf{Y})$ es cercano a 1. Sin embargo, las conclusiones con ambiguas cuando hay varios modelos con probabilidades cercanas a 1. 

El diseño MD propuesto por Box y Hill en 1967 \cite{hillybox1967} \val{Aqui tengo duda porque Meyer es el que los cita} tiene la siguiente forma. Sea \textbf{Y*} el vector de datos obtenidos de los ensayos adicionales y sea $P(\textbf{Y*} | M_i, \textbf{Y})$ la densidad predictiva de \textbf{Y*} dados los datos iniciales $\textbf{Y}$ y el modelo $M_i$. Entonces, 

\begin{equation*}
	\begin{aligned}
		MD = \sum_{0 \leq i \neq j \leq m} P(M_i | \textbf{Y}) P(M_j | \textbf{Y}) \int_{-\infty}^{infty} p(\textbf{Y*} | M_i, \textbf{Y}) \times ln(\dfrac{p(\textbf{Y*} | M_i, \textbf{Y})}{p(\textbf{Y*} | M_j, \textbf{Y})}) d\textbf{Y*}
	\end{aligned}
\end{equation*}

Sea $p_i$ la densidad predictiva para una nueva observación condicionada a las observaciones originales $Y$ and sea $M_i$ el modelo correcto. Entonces, el diseño de criterio es 

\begin{equation*}
	\begin{aligned}
		MD = \sum_{0 \leq i \neq j \leq m} P(M_i | Y)  P(M_j | Y) I(p_i, p_j)
	\end{aligned}
\end{equation*}

donde $I(p_i, p_j) = \int p_i ln(\dfrac{p_i}{p_j})$ es la información de Kullback-Leibler y mide la información media para discriminar a favor de $M_i$ contra $M_j$ cuando $M_i$ es el verdadero modelo. Además, la proporción $\dfrac{p_i}{p_j}$ puede verse como la probabilidad en favor de $M_i$ contra $M_j$ dados los datos de los experimentos extras. 

Entre mayor sea el valor de MD para un diseño, mejor ya que el diseño que maximice MD puede ser referido como el diseño \textit{MD-óptimo}. 

La intuición detrás de la fórmula del criterio MD puede ser más sencilla de entender si consideramos el ejemplo donde solo tenemos dos modelos posibles, $M_1$ y $M_2$. MD es proporcional a la suma del valor esperado de $ln(p_1/p_2)$ dado $M_1$ y el valor condicional esperado de  $ln(p_2/p_1)$ dado $M_2$. Entonces, buscamos un diseño que calcule una probabilidad alta a favor de $M_1$ si este es el modelo correcto; pero además que calcule lo mismo para $M_2$ si es el modelo correcto. En otras palabras, buscamos el valor de MD que señale el diseño correcto. 

\section{Algoritmo de intercambio}
En su artículo, \cite{mitchelldetmax} explica un algoritmo llamado 'DETMAX' para la construcción de diseños experimentales 'D-óptimos'. Lo siguiente es un resumen de dicho artículo. 

Consideremos el modelo lineal usual $y = X \beta + \epsilon$ donde $y$ es un vector de observaciones de tamaño $n \times 1$, $X$ es una matriz de $n \times k$ de constantes, $\beta$ es el vector $k \times 1$ de coeficientes para ser estimados y $\epsilon$ es un vector de $n \times 1$ de variables aleatorias independientes e idénticamente distribuidas con una media $0$ y una varianza desconocida $\sigma^{2}$. El renglón i-ésimo de $X$ es $f(x_i)'$ donde $x_i$ es el i-ésimo punto de diseño y la función $f$ depende en el modelo. Sea $p$ el número de variables independientes y $\chi$ la región donde es factible realizar experimentos.

El estimador de mínimos cuadrados de $\beta$ es $\hat{\beta} = (X'X)^{-1} X'y$, y la matriz de covarianza de $\hat{\beta}$ es $(X'X)^{-1} \sigma^{2}$. En cualquier punto $x \in \chi$, el valor estimado de la 'verdadera' respuesta es $\hat{y} (x) = f(x)' \beta$. Si el modelo es correcto, la esperanza de $\hat{y}(x)$ es la esperanza de la respuesta en el punto $x$. Es decir, el modelo predice correctamente $y$. La varianza de $\hat{y}(x)$ está dada por $v(x) = f(x)' (X'X)^{-1} f(x) \sigma^{2}$. En este caso, $\sigma^{2}$ puede ser tomada como $1$ sin pérdida de generalidad. 

Uno de los diseños más populares para construir diseños óptimos es el de maximizar $|X'X|$ llamado diseño 'D-óptimos'.  El propósito del artículo de Mitchell es presentar un nuevo algoritmo llamado DETMAX para maximizar el determinante de la matriz $X'X$. 

En primera instancia \val{Agregar que fue la referencia 5}, el algoritmo fue creado para intercambiar puntos de diseño de la siguiente manera. Empezando con un diseño elegido al azar de $n$ ensayos, el diseño original de $n$ ensayos se puede mejorar 

\valinline{Se lee muy confuso, son puntos o ensayos?}

\begin{enumerate}
	\item Sumando un ensayo número $n+1$ elegido para que se alcance el incremento máximo posible de $|X'X|$. Después, 
	\item Quitando el ensayo en el diseño resultante que resulte en la menor disminución en  $|X'X|$. 
\end{enumerate}

Estos dos pasos se llegan primero sumando al diseño original el punto donde $v(x)$ sea máximo y después restando del diseño con $n+1$ ensayos resultante el punto donde $v(x)$ es mínimo.

\valinline{Aquí quiero agregar un pequeño diagrama} 

Ahora bien, para tener mayor flexibilidad, este algoritmo básico fue modificado para permitir el reemplazamiento de más de un punto del diseño original en cada iteración. El requerimiento de que un diseño con $n+1$ puntos sea regresado inmediatamente a un diseño con $n$ puntos se relajo. Al algoritmo ahora se le permite hacer una 'excursión' donde se pueden construir diseños de varios tamaños que eventualmente regresan a un diseño de tamaño $n$.  

Si no hay mejora en el determinante todos los diseños construidos en la excursión son eliminados y puestos en un conjunto de diseños fallidos llamado $F$. El conjunto $F$ es usado después para guiar la siguiente excursión, la cual siempre empieza con el mejor diseño actual de $n$ puntos. 
Sea $D$ el diseño actual en cualquier punto durante una excursión. Las reglas para continuar con la excursión son las siguientes:

\begin{enumerate}
	\item Si el número de puntos en $D$ es mayor que $n$, quitar un punto si $D$ no está en $F$ y agregar un punto de lo contrario. 
	
	\item Si el número de puntos en $D$ es menor que $n$, agregar un punto si $D$ no está en $F$ y quitar un punto de otra manera. 
\end{enumerate}

Para determinar si algún $D$ está o no en $F$, solo se examina el determinante de $|X'X|$. A pesar de que esto no es un prueba de fuego (ya que dos diseños diferentes pueden tener el mismo determinante) parece ser una buena manera en probar equivalencias en poco tiempo. 

Cada vez se vuelve más y más difícil tener un mejor diseño por lo que las excursiones se pueden alejar mucho de un nivel de $n$ puntos. Para parar el algoritmo, Mitchell propone pone límites en el mínimo y máximo número de puntos permitidos en la construcción de un diseño durante una excursión los cuales recomienda poner estén en $n \pm 6$. 

Mitchell adopta el enfoque de Dykstra \val{Agregar referencia} en donde los puntos de diseño son seleccionados de una lista previamente especificada de candidatos. Esto trae facilidad de programación y el poder de excluir puntos que no son deseados o posibles. 

Debido a la existencia de muchos diseños que son óptimos solo localmente, lo mejor es hacer varias intentos independientes en la solución. En cada intento, DETMAX empieza con un diseño completamente nuevo cuyos puntos son seleccionados aleatoriamente de una lista de candidatos. Él determina que diez intentos usualmente son suficientes para llegar al diseño óptimo. 

\section{Función MDopt}
\cite{tesis_paty} uso la información anterior para crear la función \texttt{MDopt} en la librería \texttt{BsMD2}. Yo utilicé esa función como referencia para crear funciones del mismo nombre en Julia y Python. 

Esta función toma como entrada varios parámetros, pero los más relevantes son la matriz \texttt{X} y el número de interacciones entre factores llamado \texttt{max\_int}. Si el diseño tiene interacciones entre dos factores, la función crea una matriz \texttt{Xfac} con ellas. Lo mismo sucede si el diseño tiene interacciones entre tres factores. 

Después, la función hace el cálculo de $\Gamma_k, \beta_k, \delta_k$ con las fórmulas \ref{gamma_i}, \ref{betai} y \ref{delta_i} respectivamente. Posteriormente, se define otra función (dentro de \texttt{MDopt}) llamada \texttt{MDr} que calcula el número MD con la fórmula \val{aquí falta}. Finalmente, \texttt{MDopt} usa la idea del algoritmo de intercambio para calcular el criterio MD para múltiples combinaciones de ensayos. 

Es importante mencionar que la función \texttt{MDopt} escrita por Noyola devuelve el dataframe de todos los ensayos para los que calculo el valor de MD, la matriz X, la matriz de puntos candidatos, el vector de probabilidades para cada modelo considerado y las matrices con los factores activos para cada modelo. 

En cambio, las funciones que yo hice en Julia y Python solamente devuelven el dataframe de todos los ensayos realizados con su valor MD ya que eso es lo que necesito para mostrar los resultados. El diagrama \val{falta} muestra lo anterior de manera visual. 

\begin{figure}[h]
	\begin{center}
		\includegraphics[scale=0.5]{Imagenes/diagrama_MDopt.PNG}
		\caption{Diagrama de la función MDopt}
		\label{diagrama_mdopt}
	\end{center}
\end{figure} 

El pseudocódido de la función \texttt{MDr} y el algoritmo de intercambio están en los apéndices de \cite{tesis_paty}.  



\section{Comparación entre lenguajes}

Ya que la tesis es para probar la eficiencia y funcionalidad de Julia en comparación con R y Python use el mismo código en los tres lenguajes para ver cual de los tres hace los cálculos de MD de la manera más rápida y eficiente. En R utilice el paquete BsMD2 hecho por Ana Patricia Vela Noyola y el paquete BsMD elaborado por el profesor Ernesto Barrios. En Julia y Python utilice ese mismo código solo que adaptado a los diferentes lenguajes. Después, llamé a los códigos de Julia y Python en R para medir el tiempo que le toma a cada lenguaje ejecutar dos ejemplos distintos. 

Es importante mencionar que fue más difícil traducir el código a Python ya que este lenguaje utiliza una enumeración diferente. Los objetos en Python comienzan a contarse desde el $0$ mientras que en R y Julia la numeración empieza en $1$. Puede ser un poco confuso hacer la transición. Además, los resultados también tienen numeración diferente y, a pesar de que son exactamente iguales que en los otros lenguajes, hay que tener cuidado con su presentación para evitar confusiones. 

No es extraño que en los paquetes, \texttt{JuliaCall} y \texttt{reticulate}, existan comandos que sirvan para efectuar las mismas tareas. Por lo tanto, la siguiente tabla es una lista de los comandos que utilicé en \texttt{JuliaCall} así como su simil en \texttt{reticulate}.

\begin{tabular}{ |p{2cm}|p{2.5cm}|p{3cm}|p{3cm}|  }
	\hline
	JuliaCall & reticulate & Uso & Especificaciones\\
	\hline
	julia\_setup   & use\_python    & Es usado para especificar la dirección del programa (Julia o Python) dentro de tu computadora &   use\_python no es necesario a menos que tengas varias versiones de Python instaladas\\
	\hline
	julia\_source &   source\_python  & Agregan a R las funciones que estén dentro de los archivos especificados   & Es necesario tener la terminación del archivo correcta\\
	\hline
	julia\_assign & r\_to\_py &  Convierte los objetos de R en objetos del programa externo &  JuliaCall no agrega los objetos al ambiente de R\\
	\hline
	julia\_eval y julia\_command  & repl\_python\(\) & Corren el lenguaje externo dentro de R&  Con repl\_python, la consola de R se convierte en una de Python\\

	\hline
\end{tabular}


Para llamar Julia en R, utilice el paquete \texttt{JuliaCall}. Este paquete permite que Julia funcione dentro de R. Es decir, yo utilizo los objectos creados en R y los puedo trasladar a Julia para correr alguna función creada en Julia. El paquete es como un puente entre ambos lenguajes donde solamente hace la conexión más no los mezcla de ninguna otra forma.

En primer lugar, justo después de cargar la librería de \texttt{JuliaCall} es necesario usar el comando \texttt{julia\_setup} y poner la dirección de la carpeta donde está instalado Julia en tu computadora. Después, para cada ejemplo creo los objetos que necesito como entrada de la función. Posteriormente, utilizo el comando \texttt{julia\_assign} para asignar los objetos creados en R a objetos nuevos en Julia. En caso de que la conversión de alguno de los objetos no sea la deseada, utilizo \texttt{julia\_command} para hacer la conversión dentro de Julia. Además, debo tener la función que quiero utilizar en un documento con terminación \textsf{.jl} guardado en la carpeta de mi directorio de trabajo. Para agregar la función en R, utilizo el comando \texttt{julia\_source} y dentro el nombre del documento. Finalmente, utilizo el comando \texttt{julia\_eval} para correr la función que con los parámetros ya que cree. 

Para llamar Python en R utilice el paquete \texttt{reticulate}. Este paquete funciona más como una extensión de R ya que puedes transitar fácilmente entre ambos lenguajes sin necesidad de muchos comandos. Mas bien, lo que se necesitan son prefijos como \texttt{.r} o \texttt{py\$} para llamar los objetos de cada lenguaje.

Para utilizar la función que escribí en Python, lo primero que hice (después de llamar al paquete, claro está) es guardarla en un archivo con terminación \textsf{.py} y guardarlo en la carpeta del directorio de trabajo. Después, utilice el comando \texttt{source\_python} para llamar el archivo. Con solamente llamar el archivo se cargan en R todas las funciones dentro de él. En este caso, yo solamente tenía una función pero en caso de tener varias, solo es necesario cargar el archivo una vez. Después, debo utilizar el comando \texttt{r\_to\_py} para convertir todos los objetos de R en objetos de Python. Una de las ventajas de este paquete es que crea el objeto de Python en el ambiente de R y si usas RStudio, puedes ver el objeto creado en la parte de \textsf{Environment} de tu pantalla. Para Julia esto no pasa lo cual puede llegar a ser confuso. 

Posteriormente, si uno de los parámetros de la función es un entero te recomiendo que también los conviertas en un objeto de Python ya que en ocasiones el paquete los convierte automáticamente en objetos de tipo \texttt{Float} cuando son enteros y la función puede fallar. Finalmente, puedes llamar a tu función de Python en R sin ningún comando adicional. Lo único que necesitas es usar el nombre de la función tal cual la usaste en Python y agregarle los parámetros que ya creaste. 

\section{Ejemplos y resultados}

\subsection{Ejemplo 1 - Proceso de moldeo por inyección}

El primer ejemplo que utilice fue mencionado por \cite{meyer1996} quien lo tomo de un artículo escrito por Box, Hunter y Hunter en 1978. El experimento consiste en estudiar los efectos de ocho factores en el encojimiento de un proceso de moldeo por inyección. El plan experimental fue un $2^{8-4}$ factorial fraccionado con generadores $I = ABDH = ACEH = BCFH = ABCG$. Los datos para este ejemplo están en la tabla \ref{data_table1}. 

\begin{center}
	\begin{tabular}{ccccccccc|c}
		Ensayo & A & B & C & D & E & F & G & H & Y \\
		\hline
		1 & -1 & -1 & -1 & 1 & 1 & 1 & -1 & 1 & 14.0 \\
		
		2 & 1 & -1 & -1 & -1 & -1 & 1 & 1 & 1 & 16.8 \\
		
		3 & -1 & 1 & -1 & -1 & 1 & -1 & 1 & 1 & 15.0 \\
		
		4 & 1 & 1 & -1 & 1 & -1 & -1 & -1 & 1 & 15.4 \\
		
		5 & -1 & -1 & 1 & 1 & -1 & -1 & 1 & 1 & 27.6 \\
		
		6 & 1 & -1 & 1 & -1 & 1 & -1 & -1 & 1 & 24.0 \\
		
		7 & -1 & 1 & 1 & -1 & -1 & 1 & -1 & 1 & 27.4 \\
		
		8 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 22.6 \\
		
		9 & 1 & 1 & 1 & -1 & -1 & -1 & 1 & -1 & 22.3 \\
		
		10 & -1 & 1 & 1 & 1 & 1 & -1 & -1 & -1 & 17.1 \\
		
		11 & 1 & -1 & 1 & 1 & -1 & 1 & -1 & -1 & 21.5 \\
		
		12 & -1 & -1 & 1 & -1 & 1 & 1 & 1 & -1 & 17.5 \\
		
		13 & 1 & 1 & -1 & -1 & 1 & 1 & -1 & -1 & 15.9 \\
		
		14 & -1 & 1 & -1 & 1 & -1 & 1 & 1 & -1 & 21.9 \\
		
		15 & 1 & -1 & -1 & 1 & 1 & -1 & 1 & -1 & 16.7 \\
		
		16 & -1 & -1 & -1 & -1 & -1 & -1 & -1 & -1 & 20.3 \\
		
	\end{tabular}
	\captionof{table}{Datos para el ejemplo 1} \label{data_table1}
\end{center}

No es el objetivo de esta tesis explicar el análisis previo que se hace en este tipo de experimentos, pero sí es importante destacar que se calcula la probabilidad posterior \val{explicar más esto} de los modelos. En este análisis se ve que los posibles modelos son los que se muestran en la tabla \cite{modelos_prob_post}. 

\begin{center}
	\begin{tabular}{ccc}
		Modelo & Factores & Probabiliad posterior \\
		\hline
		1 & A,C,E & 0.2356 \\
		
		2 & A,C,H & 0.2356 \\
		
		3 & A,E,H & 0.2356 \\
		
		4 & C,E,H & 0.2356 \\
		
		5 & A,C,E,H & 0.0566 \\
		
	\end{tabular}
	\captionof{table}{Modelos con la probabilidad posterior más alta para el ejemplo 1} \label{modelos_prob_post}
\end{center}

Además, calculando las probabilidades posteriores $P_j$ mencionadas en \ref{eq_pj}, los factores \textit{A, C, E, \text{ y } H} tienen una probabilidad posterior de $0.764$ mientras que los demás factores tienen una probabilidad de $0$. Por lo tanto, los factores \textit{A, C, E, \text{ y } H} son los que parecieran ser activos. Dado el análisis previo, el problema original con un diseño de $2^{8-4}$ paso a convertirse en un modelo con diseño $2^{4-1}$ por la reducción de factores. Con los ensayos que tenemos no es posible distinguir entre los cinco posibles modelos por lo que se necesitan ensayos adicionales para aclarar cuales son los factores activos. 

La tabla \ref{extra_runs_ej1} muestra las predicciones de las respuestas para todas las combinaciones de factores \textit{A, C, E, \text{ y } H}. El propósito de esta tesis no es indagar mucho en el cálculo de estas probilidades \val{o sí?}, pero puedo decir que se calculan usando medias posteriores como estimadores de los efectos principales y sus interacciones. 

\begin{center}
	\begin{tabular}{cc|ccccc|ccccc}
		Candidato & Ensayo & A & C & E & H & Y & 1 & 2 & 3 & 4 & 5 \\
		\hline
		1 & 14, 16 & -1 & -1 & -1 & -1 & 21.9, 20.3 & 21.08 & 21.08 & 21.08 & 21.08 & 21.09 \\
		
		2 & 1, 3 & -1 & -1 & 1 & 1 & 14.0, 15.0 & 14.58 & 14.58 & 14.58 & 14.58 & 14.54 \\
		
		3 & 5, 7 & -1 & 1 & -1 & 1 & 27.6, 27.4 & 27.38 & 27.38 & 27.38 & 27.38 & 27.44 \\
		
		4 & 10, 12 & -1 & 1 & 1 & -1 & 17.1, 17.5 & 17.34 & 17.34 & 17.34 & 17.34 & 17.32 \\
		
		5 & 2, 4 & 1 & -1 & -1 & 1 & 16.8, 15.4 & 16.16 & 16.16 & 16.16 & 16.16 & 16.13 \\
		
		6 & 13, 15 & 1 & -1 & 1 & -1 & 15.9, 16.7 & 16.35 & 16.35 & 16.35 & 16.35 & 16.33  \\
		
		7 & 9, 11 & 1 & 1 & -1 & -1 & 22.3, 21.5 & 21.87 & 21.87 & 21.87 & 21.87 & 21.88 \\
		
		8 & 6, 8 & 1 & 1 & 1 & 1 & 24.0, 22.6 & 23.25 & 23.25 & 23.25 & 23.25 & 23.27 \\
		
		9 &  & -1 & -1 & -1 & 1 &  & 21.08 & 14.58 & 27.38 & 16.16 & 19.75 \\
		
		10 &  & -1 & -1 & 1 & -1 &  & 14.58 & 21.08 & 17.34 & 16.35 & 19.75 \\
		
		11 &  & -1 & 1 & -1 & -1 &   & 27.38 & 17.34 & 21.08 & 21.87 & 19.75 \\
		
		12 &  & -1 & 1 & 1 & 1 &   & 17.34 & 27.38 & 14.58 & 23.25 & 19.75 \\
		
		13 &   & 1 & -1 & -1 & -1 &   & 16.16 & 16.35 & 21.87 & 21.08 & 19.75 \\
		
		14 &   & 1 & -1 & 1 & 1 &   & 16.35 & 16.16 & 23.25 & 14.58 & 19.75 \\
		
		15 &   & 1 & 1 & -1 & 1 &   & 21.87 & 23.25 & 16.16 & 27.38 & 19.75 \\
		
		16 &   & 1 & 1 & 1 & -1 &    & 23.25 & 21.87 & 16.35 & 17.34 & 19.75 \\
		
	\end{tabular}
	\captionof{table}{Ejemplo 1, Colapsado en los factores A, C, E y H} \label{extra_runs_ej1}
\end{center}

Considero importante explicar a detalle la tabla \ref{extra_runs_ej1}. Los datos de primeros ocho candidatos son los mismos datos de la tabla \ref{data_table1}, pero mostrando únicamente los factores \textit{A, C, E, \text{ y } H}. No es una sorpresa que la respuesta \text{Y} sea similar por candidato ya que los factores que creemos están activos se mantuvieron en los mismos niveles.

Por otro lado, los siguiente ocho candidatos son todas las posibles combinaciones para los cuatro modelos con mayor probabilidad. Tomemos, por ejemplo, el modelo que dice que los factores activos son \textit{A, C, E}. Si ignoramos la columna H de la tabla \ref{extra_runs_ej1}, los 8 ensayos muestran todas las posibles combinaciones que puede tener un experimento con estos tres factores. Lo mismo pasa con los otros tres modelos con tres factores cada uno. Para el modelo final con cuatro factores activos, la tabla completa es todas las posibles combinaciones. 

Además, es importante notar que para los primeros ocho candidatos la respuesta de los modelos es similar. Mientras, para los siguientes ocho ésta varia mucho más. La similitud en las respuestas de los primeros ocho candidatos refuerza la idea de que es muy complicado distinguir entre los cinco posibles modelos. La diferencia en los siguientes ocho candidatos ayudará a que ahora sí sea posible distinguir entre los posibles modelos. 

Como se menciono anteriormente, no es posible realizar todos los ensayos posibles así que tendremos que elegir. En este caso, buscamos generar un diseño de seguimiento de cuatro ensayos usando el criterio MD. Hay $3,876$ posibles diseños que podemos generar de los 16 candidatos de la tabla \ref{extra_runs_ej1}. Se podría generar un código que calcule el valor MD para cada uno de esos diseños. Sin embargo, es mejor utilizar el algoritmo de intercambio ya que genera un diseño al azar de puntos candidatos y después los modifica hasta que un criterio de convergencia se satisface. 

El código para el cálculo del criterio MD y el algoritmo de intercambio para R, Julia y Python es el siguiente. 


\begin{minted}{R}
	# # # R paquete Patricia
	library(BsMD2)
	setwd("~/ITAM/Tesis/Julia con R/Code/MD-optimality")
	
	# matriz de diseño inicial
	X <- as.matrix(BM93e3[1:16,c(1,2,4,6,9)]) 
	# vector de respuesta
	y <- as.vector(BM93e3[1:16,10]) 
	# probabilidad posterior de los 5 modelos
	p_mod <- c(0.2356,0.2356,0.2356,0.2356,0.0566) 
	
	fac_mod <- matrix(c(2,1,1,1,1,3,3,2,2,2,4,4,3,4,3,0,0,0,0,4),
			nrow=5,
			dimnames=list(1:5,c("f1","f2","f3","f4")))
	
	Xcand <- matrix(c(1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,
	-1,-1,-1,-1,1,1,1,1,-1,-1,-1,-1,1,1,1,1,
	-1,-1,1,1,-1,-1,1,1,-1,-1,1,1,-1,-1,1,1,
	-1,1,-1,1,-1,1,-1,1,-1,1,-1,1,-1,1,-1,1,
	-1,1,1,-1,1,-1,-1,1,1,-1,-1,1,-1,1,1,-1),
	nrow=16,dimnames=list(1:16,c("blk","f1","f2","f3","f4"))
	)
	
	
	t <- Sys.time()
	e3_R <- BsMD2::MDopt(X = X, y = y, Xcand = Xcand,
	nMod = 5, p_mod = p_mod, fac_mod = fac_mod, 
	nStart = 25)
	Sys.time() - t
	
	# # # R paquete original
	library(BsMD)
	
	s2 <- c(0.5815, 0.5815, 0.5815, 0.5815, 0.4412)
	
	t_RO <- Sys.time()
	e3_RO <- BsMD::MD(X = X, y = y, nFac = 4, nBlk = 1, 
						mInt = 3, g = 2, nMod = 5, 
						p = p_mod, s2 = s2, 
						nf = c(3, 3, 3, 3, 4), 
	facs = fac_mod, nFDes = 4, Xcand = Xcand, mIter = 20, 
	nStart = 25, top = 10)
	Sys.time() - t_RO
	
	# # #  Julia con R
	library(JuliaCall)
	julia_setup(JULIA_HOME = "C:/Users/Valeria/AppData/Local/Programs/Julia-1.6.3/bin")
	
	julia_source("MDopt.jl")
	# Conversiones para los tipos de Julia
	X_J <- as.data.frame(X)
	julia_assign("X_J", X_J)
	julia_assign("y_J", y)
	julia_assign("p_mod_J", p_mod)
	julia_assign("fac_mod_J", fac_mod)
	julia_command("fac_mod_J = NamedArray(fac_mod_J)")
	julia_eval("fac_mod_J = Int64.(fac_mod_J)")
	julia_assign("Xcand_J", Xcand)
	julia_command("Xcand_J = NamedArray(Xcand_J)")
	julia_eval("Xcand_J = Int64.(Xcand_J)")
	
	t_J <- Sys.time()
	julia_eval("MDopt(X = X_J, y = y_J, Xcand = Xcand_J, nMod = 5, 
		p_mod = p_mod_J, fac_mod = fac_mod_J, nFDes = 4, 
		max_int = 3, g = 2, Iter = 20, nStart = 10, top = 10)")
	Sys.time() - t_J
	
	# # # Python con R
	library(reticulate)
	
	source_python("MD_Python.py")
	
	X_P <- as.data.frame(X)
	Xcand_P <- as.data.frame(Xcand)
	fac_mod_P <- as.data.frame(fac_mod)
	
	X_P <- r_to_py(X_P)
	y_P <- r_to_py(y) 
	Xcand_P <- r_to_py(Xcand_P)
	p_mod_P <- r_to_py(p_mod)
	fac_mod_P <- r_to_py(fac_mod_P)
	
	nMod_P <- r_to_py(5L)
	nFDes_P <- r_to_py(4L)
	max_int_P <- r_to_py(3L)
	g_P <- r_to_py(2L)
	Iter_P <- r_to_py(20L)
	nStart_P <- r_to_py(25L)
	top_P <- r_to_py(10L)
	
	t_P <- Sys.time()
	MD_Python(X = X_P, y = y_P, Xcand = Xcand_P, nMod = nMod_P, 
	p_mod = p_mod_P, fac_mod = fac_mod_P, 
	nFDes = nFDes_P, max_int = max_int_P, 
	g = g_P, Iter = Iter_P, nStart = nStart_P, top = top_P)
	Sys.time() - t_P
\end{minted}

Es importante notar que para R utilice el paquete elaborado por Patricia así como el paquete original \textbf{BsMD} elaborado por el profesor Ernesto Barrios. En los tres lenguajes los resultados fueron los mismos y se muestran en la tabla \ref{results_ej1}

\begin{center}
	\begin{tabular}{cc|c}
		Diseño & Puntos de diseño & MD \\
		\hline
		1 & 9, 9, 12, 15 & 85.67 \\
		
		2 & 9, 11, 12, 15 & 83.63 \\
		
		3 &  9, 11, 12, 12 & 82.18 \\
		
		4 & 9, 12, 15, 16 & 77.05 \\
		
		5 & 9, 12, 13, 15 & 76.74 \\
		
		6 & 9, 10, 11, 12 & 76.23 \\
		
		7 & 2, 9, 12, 15 & 71.23 \\
		
		8 & 5, 9, 12, 15 & 70.75 \\
		
		9 & 2, 9, 12, 12 & 67.69 \\
		
		10 & 9, 10, 12, 16 & 66.58 \\
		
	\end{tabular}
	\captionof{table}{Resultados para el ejemplo 1} \label{results_ej1}
\end{center}

En cuanto a tiempo, al paquete de Patricia le tomo 5.618191 segundos en hacer el cálculo; al paquete \textbf{BsMD} del profesor Barrios le tomó 0.03919315; Julia se tardó 34.85702 segundos; \val{Incluir aquí que falta el tiempo del setup} y a Python 51.05128 segundos. 

Es importante mencionar que en el caso de Julia el tiempo va disminuyendo las ocasiones consecutivas que corres el código inclusive cambiando los parámetros de la función. La segunda ocasión solo le tomo 9 segundos y la tercera 5 segundos. Esto es útil cuando se esté corrigiendo la función o simplemente se quiera correr varias veces para distintos diseños. 


\subsection{Ejemplo 2 }
En el ejemplo anterior, no había forma de replicar el experimento con los ensayos adicionales en las mismas condiciones en las que fue efectuado. El objetivo de este ejemplo, que también es tomado de Meyer \cite{meyer1996}, es evaluar la efectividad del criterio MD para generar datos que puedan identificar cuales son los factores activos.

Meyer utiliza datos de un experimento de reactor hecho por Box et al en 1978. Ese experimento es de tipo $2^{5}$ factorial lo que significa que hay 32 ensayos del mismo. Este ejemplo Meyer busca probar la efectividad de su diseño tomando solamente 8 de los 32 ensayos originales y encontrando de manera correcta los factores que están activos. La idea es tener un diseño de seguimiento que pueda tomar los ensayos adicionales necesarios del experimento original. 
Los ocho ensayos elegidos están en el tabla \ref{data_table2}. 

\begin{center}
	\begin{tabular}{cccccc|c}
		Ensayo & A & B & C & D & E & Y \\
		\hline
		1 & -1 & -1 & -1 & 1 & 1 & 44 \\
		
		2 & 1 & -1 & -1 & -1 & -1 & 53 \\
		
		3 & -1 & 1 & -1 & -1 & 1 & 70 \\
		
		4 & 1 & 1 & -1 & 1 & -1 & 93 \\
		
		5 & -1 & -1 & 1 & 1 & -1 & 66 \\

		6 & 1 & -1 & 1 & -1 & 1 & 55 \\
		
		7 & -1 & 1 & 1 & -1 & -1 & 54 \\
		
		8 & 1 & 1 & 1 & 1 & 1 & 82 \\	
		
	\end{tabular}
	\captionof{table}{Datos para el ejemplo 2} \label{data_table2}
\end{center}

En análisis bayesiano previo para los datos de la figura \ref{data_table2} no muestra de manera clara que algún factor esté activo. Por lo tanto, un diseño de cuatro ensayos fue creado para encontrar el mejor subconjunto de 4 de los 32 posibles candidatos de cinco factores en dos niveles. 

El código para generar los resultados en los tres lenguajes es el siguiente.

\begin{minted}{R}
	library(BsMD2)
	
	setwd("~/ITAM/Tesis/Julia con R/Code/MD-optimality")
	data(M96e2)
	#print(M96e2)
	
	X <- as.matrix(cbind(blk = rep(-1, 8), 
		M96e2[c(25,2,19,12,13,22,7,32), 1:5]))
	y <- M96e2[c(25,2,19,12,13,22,7,32), 6]
	
	pp <- BsProb1(X = X[, 2:6], y = y, p = .25, gamma = .4, 
	max_int = 3, max_fac = 5, top = 32)
	
	p <- pp@p_mod
	facs <- pp@fac_mod
	Xcand <- as.matrix(cbind(blk = rep(+1, 32), M96e2[, 1:5]))
	t <- Sys.time()
	e4_R <- BsMD2::MDopt(X = X, y = y, Xcand = Xcand, 
	nMod = 32, p_mod = p, fac_mod = facs, 
	g = 0.4, Iter = 10, nStart = 25, top = 5)
	Sys.time() - t
	
	library(JuliaCall)
	julia_setup(JULIA_HOME = "C:/Users/Valeria/AppData/
				Local/Programs/Julia-1.6.3/bin")
	
	julia_source("MDopt.jl")
	
	X <- as.matrix(cbind(blk = rep(-1, 8), 
		M96e2[c(25,2,19,12,13,22,7,32), 1:5]))
	y <- M96e2[c(25,2,19,12,13,22,7,32), 6]
	
	pp <- BsProb1(X = X[, 2:6], y = y, p = .25, gamma = .4, 
	max_int = 3, max_fac = 5, top = 32)
	
	p <- pp@p_mod
	facs <- pp@fac_mod
	Xcand <- as.matrix(cbind(blk = rep(+1, 32), M96e2[, 1:5]))
	
	# Conversiones para los tipos de Julia
	X <- as.data.frame(X)
	julia_assign("X", X)
	julia_assign("y", y)
	julia_assign("p_mod", p)
	julia_assign("fac_mod", facs)
	julia_command("fac_mod = NamedArray(fac_mod)")
	julia_eval("fac_mod = Int64.(fac_mod)")
	julia_assign("Xcand", Xcand)
	julia_command("Xcand = NamedArray(Xcand)")
	julia_eval("Xcand = Int64.(Xcand)")
	
	t_J <- Sys.time()
	julia_eval("MDopt(X = X, y = y, Xcand = Xcand, nMod = 32, 
		p_mod = p_mod, fac_mod = fac_mod, nFDes = 4, max_int = 3, 
		g = 0.4, Iter = 10, nStart = 25, top = 5)")
	Sys.time() - t_J
	
	
	# # # Python con R
	library(reticulate)
	
	source_python("MD_Python.py")
	
	X_P <- as.data.frame(X)
	Xcand_P <- as.data.frame(Xcand)
	fac_mod_P <- as.data.frame(facs)
	
	X_P <- r_to_py(X_P)
	y_P <- r_to_py(y) 
	Xcand_P <- r_to_py(Xcand_P)
	p_mod_P <- r_to_py(p)
	fac_mod_P <- r_to_py(fac_mod_P)
	
	nMod_P <- r_to_py(32L)
	nFDes_P <- r_to_py(4L)
	max_int_P <- r_to_py(3L)
	g_P <- r_to_py(0.4)
	Iter_P <- r_to_py(10L)
	nStart_P <- r_to_py(25L)
	top_P <- r_to_py(5L)
	
	t_P <- Sys.time()
	MD_Python(X = X_P, y = y_P, Xcand = Xcand_P, nMod = nMod_P, 
	p_mod = p_mod_P, fac_mod = fac_mod_P, 
	nFDes = nFDes_P, max_int = max_int_P, 
	g = g_P, Iter = Iter_P, nStart = nStart_P, top = top_P)
	Sys.time() - t_P
\end{minted} 

Igual que en el ejemplo anterior, para \textbf{R} utilice ambos paquetes \texttt{BsMD} y \texttt{BsMD2}. En los tres lenguajes los resultados fueron exactamente los mismo y se muestran en la tabla \ref{results_ej2}.

\begin{center}
	\begin{tabular}{cc|c}
		Diseño & Puntos de diseño & MD \\
		\hline
		1 & 4, 10, 11, 26 & 0.64 \\
		
		2 & 4, 10, 11, 28 & 0.63 \\
		
		3 & 4, 10, 12, 27 & 0.63 \\
		
		4 & 4, 10, 26, 27 & 0.63 \\
		
		5 & 4, 12, 26, 27 & 0.62 \\
		
	\end{tabular}
	\captionof{table}{Resultados para el ejemplo 2} \label{results_ej2}
\end{center}

En cuanto a tiempo, al paquete \texttt{BsMD2} le tomo 9.573741 minutos obtener los resultados; el paquete \texttt{BsMD} hizo el cálculo en 0.4537661 segundos; Julia se tardó 50.54355 segundos; y, finalmente a Python le tomó 11.058 minutos.

Es importante mencionar que este ejemplo es el más pesado computacionalmente que voy a mostrar en esta tesis. No es sorpresa que el paquete \texttt{BsMD} sea el más rápido, ya que utiliza Fortran para hacer sus cálculos. Lo que más sorprende es que Julia sea el lenguaje que quede en segundo lugar con semejante ventaja. En este caso, Julia es mínimo 10 veces más rápido que sus competidores. Incluso usando Python desde otra plataforma Julia es más rápido. Por lo tanto, este ejemplo termina demostrando la capacidad computacional que tiene Julia para este tipo de algoritmos. 







 


