\chapter{Modelos de Regresión Lineal}

\say{Una actividad importante en estadística es la creación de modelos estadísticos que, se espera, reflejen aspectos importantes del objeto de estudio con algún grado de realismo. En particular, el objetivo del análisis de regresión es construir modelos matemáticos que describan o expliquen relaciones que pueden existir entre variables}, \cite{seber2003linear}. 

El uso de la regresión como método para mostrar la relación entre dos o más variables se remonta al siglo XIX. En 1875 fue Sir Francis Galton quien, usando semillas de guisantes, hizo el primer análisis de regresión. Galton distribuyó paquetes de dichas semillas a sus amigos para que ellos las sembraran y se las regresaran. Los paquetes tenían casi el mismo peso, siendo \textit{casi} la palabra clave, ya que los paquetes tenían una variación pequeña de peso. Así, Galton pudo establecer una relación entre los pesos de las semillas \textit{madre} contra las semillas \textit{hija}, \cite{stanton2001galton}. 

Ciertamente, el análisis de regresión se ha desarrollado de acuerdo a las demandas del tiempo. Hoy en día es posible diseñar una metodología que recabe información sobre los habitantes de un país sin la necesidad de obtener entrevistar a todos y cada uno de ellos. Se toma una muestra significativa para obtener conclusiones sobre las características socioeconómicas y culturales de la población. Sin embargo, cuando el país estudiado tiene cerca de 130 millones de habitantes (como lo es México), la muestra contiene información de 15 millones de personas. La demanda actual necesita el constante desarrollo de programas con la capacidad de leer, analizar y guardar extensas cantidades de información. 

Los modelos de regresión lineal múltiple son de los más usados en la estadística como una primera aproximación a análisis más complejos. El propósito de este capítulo es mostrar el uso de la regresión lineal múltiple  en \textsf{Julia, R} y \textsf{Python} con un gran número de datos obtenidos del Censo de Población y Vivienda 2020.  


\section{El modelo}
En capítulos anteriores se habló de la regresión lineal múltiple cuyo modelo se vuelve a considerar en este capítulo. El modelo se define como 
\begin{equation} \label{rlm_eq}
    \begin{aligned}
    y_i &= \beta_0 + \beta_i X_{i1} + \dots + \beta_k X_{ik} + \epsilon_i \text{, para } \\
    i &= 1, \dots, n \\ 
    k &= 1, \dots, p 
	\text{ \cite[p.~146]{regression_other_stories}}
    \end{aligned}
\end{equation}

\noindent donde $\epsilon_i$ representa el error del modelo que en el caso más elemental se supone sigue una distribución normal con media cero y desviación estándar $\sigma$. En este caso, $y_i$ se refiere a la respuesta al $i$-ésimo de los regresores; $x_{ik}$ es el $k$-ésimo regresor al $i$-ésimo nivel; $\beta_0$ y $\beta_k$ son los coeficientes del modelo.

Es útil entender el modelo con un ejemplo. Imagine que trabaja en un laboratorio donde se estudia el crecimiento de girasoles. Se tienen 50 plantas que se exponen a diferentes cantidades de agua, luz solar y tierra con abono. Se busca relacionar el crecimiento de los girasoles con cambios en los factores ambientales. Por lo tanto, se tiene una tabla donde en la primera columna se documenta el crecimiento de cada planta medido en centímetros. La siguientes tres columnas registran las cantidades de agua, luz solar y tierra a la que se expone cada girasol. Por tanto, cada renglón representa uno de los 50 girasoles del experimento. 

La variable respuesta $y_i$ se refiere al crecimiento del girasol $i$-ésimo. Como hay 50 plantas, $n = 50$. Por otro lado, los regresores son el agua, la luz solar y la tierra con abono. Sea el agua el primer regresor, $x_{9,1}$ representa el nivel de agua del girasol 9. Lo mismo sucede con la luz y tierra. En este caso, $k = 3$ ya que hay tres regresores. Finalmente, $\beta_k$ es el efecto que tienen los regresores en el crecimiento de los girasoles. 

De manera matricial, \cite[p.~146]{regression_other_stories} define la expresión \ref{rlm_eq} como 

\begin{equation*}
    \begin{aligned}
    y_i = X_i \beta + \epsilon_i \text{, para } i = 1, \dots, n
    \text{ \cite[p.~146]{regression_other_stories}}
    \end{aligned}
\end{equation*}

\noindent donde $X_i$ es el $i$-ésimo renglón de la matriz $X$ de dimensión $n \times k$. Adicionalmente, se pide que la matriz $X$ sea de rango completo cuyas razones no se discuten en este trabajo. 

\section{Los datos}
Siguiendo con la idea de \cite{seber2003linear} como ejemplo se decidió relacionar el ingreso del mexicano con factores que le influyen. La información se obtuvo del  Censo de Población y Vivienda (Censo) 2020 se publicó por el Instituto Nacional de Estadística y Geografía (INEGI) que se encuentra en la página \url{https://www.inegi.org.mx/programas/ccpv/2020/default.html}. En México, el Censo se captura cada 10 años y se busca tener una muestra de todo el territorio nacional. 

De acuerdo al INEGI, el Censo es \say{es producir información sobre el volumen, la estructura y la distribución espacial de la población, así como de sus principales características demográficas, socioeconómicas y culturales; además de obtener la cuenta de las viviendas y sus características tales como los materiales de construcción, servicios y equipamiento, entre otros}, \ref{censo_ref}. \val{Arreglar esta referencia}

Recabar la información anterior es una labor demandante que se divide en dos tipos de cuestionarios llamados \say{básico} y \say{ampliado}. En el cuestionario ampliado las preguntas incluyen especificaciones sobre los residentes del territorio nacional, las viviendas particulares y los migrantes internacionales. Mientras que el básico busca información general centrada en obtención de servicios públicos en el hogar y escolaridad de sus residentes. 

En este trabajo los resultados que se utilizan provienen del cuestionario ampliado cuyas 103 preguntas resultan en cerca de 200 variables de estudio. Más aún, el Censo fue aplicado a 4 millones de viviendas a lo largo de la República Mexicana que resultó en la obtención de información de más de 15 millones de personas.

En este ejercicio se eligió un tema de interés personal: los ingresos. Más específicamente, se usa la regresión lineal múltiple para observar el efecto de diferentes factores al ingreso de cada persona. Usualmente, los modelos se basan en una mezcla de teoría, lógica, experiencia y referencias. En este caso, el modelo propuesto es 


\begin{equation} \label{modelo_final}
    \begin{aligned}
    	y =& \beta_0 + \beta_1*horas_{trabajadas} + \beta_2*sexo + \\
    	&\beta_3*edad + \beta_4*escolaridad + \beta_5*entidad_{trabajo} + \\ &\beta_6*posicion_{laboral} + \beta_7*alfabetismo + \beta_8*aguinaldo + \\ &\beta_9*vacaciones + \beta_{10}*servicio_{medico}
    \end{aligned}
\end{equation}


\section{Planteamiento del problema}
En Censo mexicano es un estudio extensivo sobre la vida de sus habitantes. El área de interés determina el filtro de información y la selección de columnas. Para esto, es necesario entender la estructura de las encuestas y la relación entre ellas. Para ello, el INEGI también proporciona el diccionario ampliado que se encuentra en la página \url{https://www.inegi.org.mx/programas/ccpv/2020/default.html#Microdatos} dentro del apartado \textsf{Documentación de la base de datos}. La información que aporta el diccionario es clave ya que expone como los códigos y las nomenclaturas que permiten entender como se paso de tener respuestas en hojas de papel a tenerlas en una base de datos.

Los resultados del Censo se dividen en tres partes: Viviendas, Personas y Migrantes. Para este trabajo, se utilizó la base de datos correspondientes a Personas ya que contiene la información necesaria para llevar a cabo el ajuste del modelo de ingresos propuesto en \ref{modelo_final}. El volumen de datos con el que se trabajo es amplio por lo que lo primero fue seleccionar los regresos necesarios de la base de datos. Posteriormente, se agregaron los siguientes filtros:

\begin{enumerate}
    \item Se seleccionaron solamente las personas que tienen un trabajo remunerado. Es decir, no se consideró a las personas que
    se ocupan de las labores del hogar, son jubiladas o pensionadas, son estudiantes o tienen alguna incapacidad que les impida tener un sueldo. 
    
    \item Se descartó a las personas que viven y trabajan fuera de la República Mexicana. 
    
    \item Se seleccionaron a las personas que especificaron horas trabajadas e ingreso ganado.
    
    \item Cada regresor es resultado de una pregunta hecha y tiene una variable asignada. Si el entrevistado decide no responder a alguna pregunta se marca la respuesta como \texttt{No especificado}. En este caso, se eliminaron a las personas que no respondieron alguna de las preguntas que corresponden a los regresores. 
\end{enumerate}

Con los filtros anteriores la cantidad de datos con los que se trabaja se reduce de 15 a 3.5 millones. Este proceso toma alrededor de 20 minutos en ejecutarse y, posteriormente, se guarda la nueva base de datos. El filtrado de la información se ejecutó en \textsf{Julia} y se guardó para utilizarla posteriormente en \textsf{R} y \textsf{Python}. El código de lectura de la base de datos y los comandos utilizados para la selección de información son los siguientes. A pesar de ser un código largo, está debidamente documentado. 


\begin{minted}{julia}
	# # # Inicio de código para filtrado de datos
	julia> using CSV, DataFrames, StatsBase, 
		GLM, Random, CategoricalArrays

	# Equivalente a set.seed de R
	julia> Random.seed!(99)

	# Leer la base de datos 
	# (toma alrededor de 4 minutos en cargar)
	julia> personas = CSV.read("Personas00.csv", DataFrame)

	# Lista con columnas necesarias para el ajuste
	julia> col_sel = ["ID_PERSONA", "SEXO", "EDAD", 
	"NIVACAD", "ALFABET", "INGTRMEN","HORTRA", "SITTRA", 
	"ENT_PAIS_TRAB", "AGUINALDO", "VACACIONES", 
	"SERVICIO_MEDICO", "CONACT", "ENT"]
         
	# Se seleccionan de la base de datos 
	julia> personas_filt = personas[:, col_sel]    

	# # # FILTRO 1
	julia> cond_act = [10, 13, 14, 15, 16, 17, 18, 19, 20]
	julia> personas_filt = subset(personas_filt, 
		:CONACT => ByRow(in(cond_act)), 
		skipmissing = true)

	# # # FILTRO 2
	julia> personas_filt = subset(personas_filt, 
		:ENT_PAIS_TRAB => ByRow(<(33)), 
		skipmissing = true)

	julia> personas_filt = subset(personas_filt, 
		:ENT => ByRow(<(33)), skipmissing = true)

	# # # FILTRO 3
	julia> personas_filt = subset(personas_filt, 
		:HORTRA => ByRow(!=(999)), skipmissing = true)

	julia> personas_filt = subset(personas_filt, 
		:INGTRMEN => ByRow(!=(999999)), 
		skipmissing = true)

	# # # FILTRO 4
	julia> function diferente_a(dataframe, columna, condicion)
    	dataframe = subset(dataframe, 
    	columna => ByRow(!=(condicion)), skipmissing = true)
    
    	return dataframe
	end

	julia> categorias_9 = ["SEXO", "AGUINALDO", "VACACIONES", 
	"SERVICIO_MEDICO", "ALFABET", "SITTRA"]

	julia> categorias_99 = ["NIVACAD"]

	julia> for i = 1:length(categorias_9)
    	personas_filt = diferente_a(personas_filt, 
    	categorias_9[i], 9)
	end

	julia> for i = 1:length(categorias_99)
    	personas_filt = diferente_a(personas_filt, 
    	categorias_99[i], 99)
	end

	# Finalmente, se guarda el nuevo dataframe
	julia> CSV.write("personas_filtradas.csv", personas_filt)
\end{minted}


\section{Factores y Sub-ajustes} \label{reg_categorias}

Lo primero que se debe verificar es que la lectura de datos haya clasificado las variables de manera correcta. En el modelo presentada en \ref{modelo_final}, la mayoría de las variables del ajuste son categoría o factores, pero \textsf{Julia} las lee como \textsf{Int64}. Por ejemplo, la variable \texttt{NIVACAD} responde a la pregunta sobre el último año o grado aprobado por el entrevistado. Hay 15 respuestas que corresponden a todos los niveles académicos posibles, desde no haber recibido ningún tipo de educación formal hasta haber obtenido un doctorado. Cada respuesta se identifica con un número que va del 0 al 14. Por lo tanto, en el modelo propuesto \ref{modelo_final}, el regresor \texttt{NIVACAD} es de tipo categórico y tiene 15 niveles. Ya que las respuestas son número, el comando \texttt{CSV.read} de \textsf{Julia} identifica incorrectamente la columna como tipo \textsf{Int64}. Esto sucede con todos los factores del modelo compilados en la lista \texttt{categorias} del código mostrado a continuación. Además, se muestra la manera en la que se convirtieron las variables a factores. 

\begin{minted}{julia}
	julia> using DataFrames
	julia> data = CSV.read("personas_filtradas.csv", DataFrame)

	# Vector con todas las categorias
	julia> categorias = ["SEXO", "AGUINALDO", "VACACIONES", 
	"SERVICIO_MEDICO", "ALFABET", "NIVACAD", "ENT_PAIS_TRAB", 
	"ENT", "SITTRA"]

	julia> transform!(data, 
		names(data, vector_categorias) .=> categorical, 
		renamecols=false)
\end{minted}

Si se omitiera el paso anterior el resultado del ajuste no tendría sentido ya que se considerarían a los regresores de tipo categórico como variables continuas. Por tanto, no proporcionarían el efecto de cada categoría en la variable de respuesta.

Uno de los objetivos de este trabajo es ilustrar las capacidades de los tres lenguajes de programación por lo que se tomó el modelo \ref{modelo_final} y se retiraron algunas variables. Se puede pensar como que se tomaron diferentes subconjuntos de variables y, con ellas, se hizo el ajuste de las regresiones para notar si había cambios en la precisión del ajuste. La variable de respuesta es la misma en todos los ahora denominados \textit{sub-ajustes}.

El primer \textit{sub-ajuste} se definió con los primeros 5 regresores del modelo \ref{modelo_final} se nombró como \textsf{fit5} (por la cantidad de regresores). Es decir, el modelo \textsf{fit5} es 

\begin{equation*}
    \begin{aligned}
 	y =& \beta_0 + \beta_1*horas_{trabajadas} + \beta_2*sexo + \\
    	&\beta_3*edad + \beta_4*escolaridad + \beta_5*entidad_{trabajo} 
    \end{aligned}
\end{equation*}


El segundo \textit{sub-ajuste} llamado \textsf{fit6} tiene los 5 regresores incluidos en \textsf{fit5} y uno extra, la posición laboral. Por tanto, el modelo \textsf{fit6} queda de la siguiente manera: 

\begin{equation*}
    \begin{aligned}
    	y =& \beta_0 + \beta_1*horas_{trabajadas} + \beta_2*sexo + \\
    	&\beta_3*edad + \beta_4*escolaridad + \beta_5*entidad_{trabajo} + \\
    	& \beta_6*posicion_{laboral}
    \end{aligned}
\end{equation*}

Las ecuaciones \textsf{fit5} y \textsf{fit6} siguen el mismo orden que \ref{modelo_final}. Esto no es una coincidencia. El orden de los regresores del modelo \ref{modelo_final} está pensado precisamente para que cada variable sumada se agregue al conjunto de variables anterior y cree un nuevo modelo \textsf{fit}.

\subsection{Código en Julia}

Sería interesante ver la reacción de Galton si supiera los alcances a los que ha llegado su experimento de semillas. Él mismo estaría de acuerdo con que no es lo mismo hacer un ajuste con 5 observaciones a hacer uno con 5 millones de ellas. El código es el mismo, pero en el trabajo de máquina se observan cambios en tiempo de ejecución y precisión numérica. Ambos factores son las razones por las que se eligió este ejercicio. En esta sección se muestra como se midieron dichos cambios.

Cada una de las ecuaciones \textsf{fit} ya mencionadas se ejecutaron con muestras de 500, 5 mil, 50 mil, 500 mil y 2.5 millones de observaciones. Es decir, se usaron cada una de las ecuaciones \textsf{fit} para el ajuste de modelos con los volúmenes de información antes mencionados. La elección de observaciones se hizo al azar usando el comando \texttt{sample} en \textsf{Julia}. Una vez seleccionadas, se guardaba el dataframe generado para usar exactamente los mismos datos en \textsf{R}, \textsf{Python} y todos los ajustes. Guardar las muestras generadas tiene el propósito de poder utilizar la misma información en los ajustes y obtener así, un punto de comparación en la precisión del cálculo de los coeficientes. 

La ejecución de lo anterior es repetitivo por lo que se buscó fuera hecho de la manera más rápida y eficiente posible. Se desarrolló una función para cada \textsf{fit} cuyos argumentos fueran la cantidad de observaciones que se está utilizaron y el nombre con el que se guarda el archivo. El nombre de las funciones coinciden con la cantidad de regresores que se están utilizando. 

Inclusive con este acercamiento, se puede notar que crear una función para cada modelo resulta repetitivo. Se pudo haber desarrollado una sola función que también tomara como argumento la fórmula a utilizarse en el ajuste. Sin embargo, se decidió no hacerlo de esa forma ya que se consideró de suma importancia tener la fórmula escrita en cada función. 

Debido a la similitud entre funciones y su ejecución se muestran solamente las correspondientes a \textsf{fit5} y \textsf{fit10} a manera de ejemplo. El código para la función \textsf{fit5} es el siguiente.

\begin{minted}{julia}
	### FIT BASE ###
	julia> function fit5(cantidad_sample, nombre_facil)
    	nombre_fit = "fit5"
    # Selección aleatoria de datos
    	sample_rows = sample(1:nrow(data), 
    		cantidad_sample, replace=false)
    	df_sample = data[sample_rows, :]
    # Generación de nombre para el archivo de salida
    	nombre_completo = nombre_facil*"_"*nombre_fit*".csv"
    # Guardar la muestra para usarla en R y Python
    	CSV.write(nombre_completo, df_sample)

    # Se hace el ajuste
    	sample_fit = lm(@formula(INGTRMEN ~ HORTRA + SEXO + 
    		EDAD + NIVACAD + ENT_PAIS_TRAB), df_sample)
	# Se guardan los resultados en otro archivo
    	aux = "res_"
    	nombre_completo = aux*nombre_completo
    	CSV.write(nombre_completo, coeftable(sample_fit))
	end 

	# Se aplica la función para las observaciones
	julia> fit5(500, "500")
	julia> fit5(5000, "5mil")
	julia> fit5(50000, "50mil")
	julia> fit5(500000, "500mil")
	julia> fit5(2500000, "2500mil")

\end{minted}

Por otro lado, el código para \textsf{fit10} es el siguiente. 

\begin{minted}{julia}
	### FIT 10###
	julia> function fit10(cantidad_sample, nombre_facil)
    	nombre_fit = "fit10"
    # Selección aleatoria de datos
    	sample_rows = sample(1:nrow(data), cantidad_sample, 
    		replace=false)
    	df_sample = data[sample_rows, :]
    # Generación de nombre para el archivo de salida
    	nombre_completo = nombre_facil*"_"*nombre_fit*".csv"
    # Guardar la muestra para usarla en R y Python
    	CSV.write(nombre_completo, df_sample)

    # Se hace el ajuste
    	sample_fit = lm(@formula(INGTRMEN ~ HORTRA + SEXO + 
    		EDAD + NIVACAD + ENT_PAIS_TRAB + SITTRA + 
    		ALFABET + AGUINALDO + VACACIONES +
    		SERVICIO_MEDICO), df_sample)
	# Se guardan los resultados en otro archivo
    	aux = "res_"
    	nombre_completo = aux*nombre_completo
    	CSV.write(nombre_completo, coeftable(sample_fit))
	end 

	# # # Fit 10: Fit 5 + SITTRA + ALFABET + AGUINALDO + 
	# # # VACACIONES + SERVICIO_MEDICO
	julia> fit10(500, "500")
	julia> fit10(5000, "5mil")
	julia> fit10(50000, "50mil")
	julia> fit10(500000, "500mil")
	julia> fit10(2500000, "2500mil")

\end{minted}

\section{Resultados y Conclusiones}

En cualquiera de los \textit{sub-ajustes}, la mayoría de los regresores son de tipo categórico por lo cual tiene diferentes niveles. La variable \textsf{NIVACAD} comentada en la sección anterior es un ejemplo de ello. Otro ejemplo es la variable llamada \textsf{ENT\_PAIS\_TRAB} que corresponde a la entidad mexicana donde el entrevistado trabajó más recientemente. Ya que México se divide en 32 entidades federativas, cada estado representa un nivel del regresor.  Si se cuentan los niveles de cada factor, al final en el modelo con más variables \textsf{fit10} se tiene un total de 54 regresores. La tabla \ref{res_fit10_2500mil} es una muestra resumida de los resultados obtenidos en \textsf{Julia} usando 2.5 millones de observaciones en el modelo \textsf{fit10}.  


\valinline{Alguna idea para arreglar esta tabla?}
\begin{center}
	\begin{tabular}{|S|c|c|c|c|c|c|} 
		\hline
		Nombre & Coeficiente & \multicolumn{1}{M}{Error estándar}  & \multicolumn{1}{M}{t} & Pr($>|t|$) & \multicolumn{1}{M}{95\% inferior}  & \multicolumn{1}{M}{95\% superior} \\ 
		\hline 
		Ordenada al origen & 4133.26 & 125.42 & 32.95 & $4.16e^{-238}$ & 3887.43 & 4379.09\\ 
		
		SEXO:3 & -1407.49 & 20.27 & -69.42 & 0 & -1447.23 & -1367.76 \\ 
		
		EDAD & 33.30 & 0.72 & 46.12 & 0 & 31.88 & 34.71 \\ 
		
		NIVACAD:1 & 208.16 & 209.00 & 0.99 & 0.32 & -201.48 & 617.80 \\
		
		NIVACAD:2 & 287.16 & 68.59 & 4.18 & $2.38e^{-05}$ & 152.72 & 421.60 \\
		
		NIVACAD:3 & 629.53 & 71.20 & 8.84 & $9.42e^{-19}$ & 489.98 & 769.08 \\
		
		\vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots \\
		
		SITTRA:3 & -692.44 & 32.10 & -21.57 & $3.30e^{-103}$ & -755.35 & -629.53 \\
		
		ALFABET:3 & -544.43 & 66.47 & -8.19 & $2.59e^{-16}$ & -674.70 & -414.16 \\
		
		AGUINALDO:2 & -459.48 & 34.30 & -13.39 & $6.51e^{-41}$ & -526.71 & -392.25 \\
		
		VACACIONES:4 & -843.60 & 38.65 & -21.83 & $1.31e^{-105}$ & -919.35 & 7678.85 \\
		
		SERVICIO \_MEDICO:6 & -1110.25 & 34.21 & -32.46 & $4.91e^{-231}$ & -1177.30 & -1043.21 \\
	
		\hline
	\end{tabular} 
	\captionof{table}{Resultados para el modelo fit10 con 2.5 millones de observaciones en Julia} \label{res_fit10_2500mil}
\end{center}

Como se observa en la tabla \ref{res_fit10_2500mil}, \textsf{Julia} no solo da el cálculo de los coeficientes, también da indicadores como lo son el error estándar y el intervalo de confianza. 

En \textsf{R} se utilizó la función \texttt{lm} para hacer los ajustes mientras que en \textsf{Python} la función \texttt{LinearRegression()} del paquete \texttt{sklearn} explicado a detalle en la sección \ref{sec_sklearn}. El código completo en ambos lenguajes se encuentra en el apéndice \ref{apendice_censo}. 

Los tres lenguajes hacen el ajuste de manera correcta y con le mismo nivel de precisión. En la tabla \ref{comparacion_precision} se presenta una comparativa de los resultados obtenidos en los tres lenguajes usando el \textit{sub-ajuste} \textsf{fit10} con 2.5 millones de datos. A manera de ejemplo, se seleccionaron todos los regresores continuos y un nivel de cada regresor categórico. Asimismo, en la tabla se omitió redondear los resultados del ajuste para observar que el nivel de precisión. En este caso, la precisión numérica se mantuvo igual en los tres lenguajes. 

\begin{center}
	\begin{tabular}{|c|c|c|c|} 
		\hline
		Regresor & Julia & R  & Python  \\ 
		\hline 
		Ordenada al origen & 4044.00297 & 4044.00297 & 4044.00297 \\ 
		
		HORTRA & 41.12933 & 41.12933 & 41.12933 \\
		
		SEXO:3 & -1403.30415 & -1403.30415 & -1403.30415 \\ 
		
		EDAD & 34.34650 & 34.34650 & 34.34650 \\ 
		
		NIVACAD:9 & 4276.80672 & 4276.80672 & 4276.80672 \\
		
		ENT\_PAIS\_TRAB:13 & -671.72888 & -671.72888 & -671.72888 \\
		
		SITTRA:2 & -668.43938 & -668.43938 & -668.43938 \\
		
		ALFABET:3 & -534.68337 & -534.68337 & -534.68337 \\
		
		AGUINALDO:2 & -483.42688 & -483.42688 & -483.42688 \\
		
		VACACIONES:4 & -812.44030 & -812.44030 & -812.44030 \\
		
		SERVICIO\_MEDICO: 6 & -1118.54895 & -1118.54895 & -1118.54895 \\
		
		\hline
	\end{tabular} 
	\captionof{table}{Comparación de resultados para el modelo fit10 con 2.5 millones de observaciones en R, Julia y Python} \label{comparacion_precision}
\end{center}

\valinline{Agrego las tablas de tiempos en el apéndice?}
En cuanto a tiempos, los tres lenguajes presentan un aumento de tiempo a medida que aumenta el volumen de observaciones a ajustar. Sin embargo, el aumento de regresores no parece tener un efecto en el tiempo de ejecución del ajuste. El lenguaje que ejecuta el cálculo de los coeficientes más rápidamente es \textsf{Julia} con un tiempo máximo de 14.19 segundos. Sin embargo, el desempeño del código completo toma más tiempo ya que a \textsf{Julia} le toma una cantidad considerable de tiempo guardar los resultados en un archivo de tipo \textsf{CSV}. 

Por otro lado, el tiempo máximo que le toma \textsf{Python} calcular un ajuste es de 18.31 segundos. Sin embargo, la diferencia de 4 segundos entre \textsf{Python} y \textsf{Julia} se compensa con la rapidez que le toma a \textsf{Python} ejecutar el código completo. Por tanto, \textsf{Julia} hace el ajuste más rápido mientras que \textsf{Python} ejecuta el código entero en la menor cantidad de tiempo. 

En cambio, \textsf{R} es el lenguaje más lento de la triada de lenguajes. Su tiempo mínimo de ejecución es de 34.16 segundos mientras que el tiempo máximo es de 1.75 minutos. Adicionalmente, el lenguaje presenta dificultades al manejar grandes cantidades de datos. Se presentó una sensación de entorpecimiento en la ejecución del código ya que los cálculos eran lentos y, en ocasiones, se presentaba un mensaje que pedía reiniciar la sesión de \textsf{R}.   

En suma, en este ejemplo el paquete \texttt{GLM} de \textsf{Julia} cumple su propósito de ajustar el modelo de manera correcta y rápida. Más aún, el paquete también proporciona los estimadores necesarios para un análisis completo de regresión. En cambio, si bien las funciones utilizadas en \textsf{R} y \textsf{Python} no presentan dicha tabla, sí existen los comandos para obtener los estimadores. 

Los tres lenguajes \textsf{Julia, R} y \textsf{Python} proporcionan herramientas que permiten leer una base de datos y ajustar un modelos lineal de manera precisa. Además, los lenguajes ofrecen herramientas para calcular los estimadores clave para hacer un análisis de regresión. Las diferencias entre los lenguajes se presentan al considerar el tiempo de ejecución y el rendimiento. \textsf{Julia} y \textsf{Python} realizan el ajuste de manera rápida y fluida, sin saturaciones de memoria o falta de respuesta del lenguaje. En cambio, \textsf{R} presenta complicaciones en el manejo de bases de datos extensas. En consecuencia, es el lenguaje más lento en realizar el ajuste y pide el constante reinicio de la sesión en la que se está trabajando. 

Los obstáculos presentados con \textsf{R} dieron pie a la realización de que, hasta este punto, la ejecución de \textsf{Julia} nunca ha presentado fallas. Investigando sobre las capacidades de \textsf{Julia} se encontró en repetidas ocasiones que tiene un propósito muy claro: ser  el lenguaje más eficiente con la mayor cantidad de aplicaciones posible. Por lo tanto, en el siguiente capítulo se cambia el enfoque de análisis de regresión para ilustrar un ejemplo de discriminación de modelos en diseños de experimentos. El objetivo del problema es mostrar la capacidad de los lenguajes de ejecutar una función que conlleva una gran cantidad de cálculos complejos. 

