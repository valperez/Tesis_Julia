\chapter{Modelos de Regresión Lineal} \label{cap_rlm}

\say{Una actividad importante en estadística es la creación de modelos estadísticos que, se espera, reflejen aspectos importantes del objeto de estudio con algún grado de realismo. En particular, el objetivo del análisis de regresión es construir modelos matemáticos que describan o expliquen relaciones que pueden existir entre variables}, \cite{seber2003linear}. 

El uso de la regresión como método para mostrar la relación entre dos o más variables se remonta al siglo XIX. En 1875 fue Sir Francis Galton quien, usando semillas de guisantes, hizo el primer análisis de regresión. Galton distribuyó paquetes de dichas semillas a sus amigos para que ellos las sembraran y le regresaran el resultado. Los paquetes tenían casi el mismo peso, siendo \textit{casi} la palabra clave, ya que existía una variación pequeña de peso. Así, Galton pudo establecer una relación entre los pesos de las semillas \textit{madre} contra las semillas \textit{hija}, \cite{stanton2001galton}. 

Ciertamente, el análisis de regresión se ha desarrollado de acuerdo a las demandas del tiempo. Hoy en día es posible diseñar una metodología que recabe información sobre los habitantes de un país sin la necesidad de entrevistar a todos y cada uno de ellos. Se toma una muestra significativa que busca obtener conclusiones sobre las características socioeconómicas y culturales de la población. Sin embargo, cuando el país estudiado tiene cerca de 130 millones de habitantes (como es el caso de México), la muestra resultante es el Censo de Población y Vivienda que contiene información de 15 millones de personas. La demanda actual necesita el constante desarrollo de programas con la capacidad de leer, analizar y guardar extensas cantidades de información. 

Los modelos de regresión lineal múltiple son de los más usados en la estadística como una primera aproximación a análisis más complejos. El propósito de este capítulo es mostrar el uso de la regresión lineal múltiple  en \textsf{Julia, R} y \textsf{Python} con un gran número de datos obtenidos del Censo de Población y Vivienda 2020.  


\section{El modelo}
En capítulos anteriores se habló de la regresión lineal múltiple cuyo modelo se vuelve a considerar en este capítulo. El modelo se define como 
\begin{equation} \label{rlm_eq}
    \begin{aligned}
    y_i &= \beta_0 + \beta_i X_{i1} + \dots + \beta_k X_{ik} + \epsilon_i \text{, para } \\
    i &= 1, \dots, n \\ 
    k &= 1, \dots, p 
	\text{ \cite[p.~146]{regression_other_stories}}
    \end{aligned}
\end{equation}

\noindent donde $\epsilon_i$ representa el error del modelo que en el caso más elemental se supone sigue una distribución normal con media cero y desviación estándar $\sigma$. En este caso, $y_i$ se refiere a la respuesta al $i$-ésimo de los regresores; $x_{ik}$ es el $k$-ésimo regresor al $i$-ésimo nivel; $\beta_0$ y $\beta_k$ son los coeficientes del modelo.

Es útil entender el modelo con un ejemplo. Imagine que trabaja en un laboratorio donde se estudia el crecimiento de girasoles. Se tienen 50 plantas que se exponen a diferentes cantidades de agua, luz solar y tierra con abono. Se busca relacionar el crecimiento de los girasoles con cambios en los factores ambientales. Por lo tanto, se tiene una tabla donde en la primera columna se documenta el crecimiento de cada planta medido en centímetros. La siguientes tres columnas registran las cantidades de agua, luz solar y tierra a la que se expone cada girasol. Por tanto, cada renglón representa uno de los 50 girasoles del experimento. 

La variable respuesta $y_i$ se refiere al crecimiento del girasol $i$-ésimo. Como hay 50 plantas, $n = 50$. Por otro lado, los regresores son el agua, la luz solar y la tierra con abono. Sea el agua el primer regresor, $x_{9,1}$ representa el nivel de agua del girasol 9. Lo mismo sucede con la luz y tierra. En este caso, $k = 3$ ya que hay tres regresores. Finalmente, $\beta_k$ es el efecto que tienen los regresores en el crecimiento de los girasoles. 

De manera matricial, Gelman define la expresión \ref{rlm_eq} como 

\begin{equation*}
    \begin{aligned}
    y_i = X_i \beta + \epsilon_i \text{, para } i = 1, \dots, n
    \text{ \cite[p.~146]{regression_other_stories}}
    \end{aligned}
\end{equation*}

\noindent donde $X_i$ es el $i$-ésimo renglón de la matriz $X$ de dimensión $n \times k$. Adicionalmente, se pide que la matriz $X$ sea de rango completo cuyas razones no se discuten en este trabajo. 

\section{Los datos}
Siguiendo con la idea de \cite{seber2003linear} se decidió tomar como ejemplo para este proyecto la relación entre el ingreso del mexicano con factores que le influyen. La información se obtuvo del  Censo de Población y Vivienda (Censo) 2020 publicado por el Instituto Nacional de Estadística y Geografía (INEGI) que se encuentra en la página \url{https://www.inegi.org.mx/programas/ccpv/2020/default.html}. En México, el Censo se captura cada 10 años y se busca tener una muestra de todo el territorio nacional. 

De acuerdo al \cite{censo_ref}, el objetivo del Censo \say{es producir información sobre el volumen, la estructura y la distribución espacial de la población, así como de sus principales características demográficas, socioeconómicas y culturales; además de obtener la cuenta de las viviendas y sus características tales como los materiales de construcción, servicios y equipamiento, entre otros}.

Recabar la información anterior es una labor demandante que se divide en dos tipos de cuestionarios llamados \say{básico} y \say{ampliado}. En el cuestionario ampliado las preguntas incluyen especificaciones sobre los residentes del territorio nacional, las viviendas particulares y los migrantes internacionales. Mientras que el básico busca información general centrada en el acceso a servicios públicos en el hogar y la escolaridad de sus residentes. 

En este trabajo los resultados que se utilizan provienen del cuestionario ampliado cuyas 103 preguntas resultan en cerca de 200 variables de estudio. Más aún, el Censo fue aplicado a 4 millones de viviendas a lo largo de la República Mexicana que resultó en la obtención de información de más de 15 millones de personas.

En este ejercicio se eligió un tema de interés personal: los ingresos. Más específicamente, se usa la regresión lineal múltiple para observar el efecto de diferentes factores al ingreso de cada persona. Usualmente, los modelos se basan en una mezcla de teoría, lógica, experiencia y referencias. En este caso, el modelo propuesto es 


\begin{equation} \label{modelo_final}
    \begin{aligned}
    	y =& \beta_0 + \beta_1*horas_{trabajadas} + \beta_2*sexo + \\
    	&\beta_3*edad + \beta_4*escolaridad + \beta_5*entidad_{trabajo} + \\ &\beta_6*posicion_{laboral} + \beta_7*alfabetismo + \beta_8*aguinaldo + \\ &\beta_9*vacaciones + \beta_{10}*servicio_{medico}
    \end{aligned}
\end{equation}


\section{Planteamiento del problema}
El Censo mexicano es un estudio extensivo sobre la vida de sus habitantes. El área de interés determina el filtro de información y la selección de columnas. Es necesario entender la estructura de las encuestas y la relación entre ellas. Para ello, el INEGI también proporciona el diccionario ampliado que se encuentra en la página \url{https://www.inegi.org.mx/programas/ccpv/2020/default.html#Microdatos} dentro del apartado \textsf{Documentación de la base de datos}. La información que aporta el diccionario es clave ya que expone los códigos y las nomenclaturas que permiten entender como se paso de tener respuestas en hojas de papel a tenerlas en una base de datos.

Los resultados del Censo se dividen en tres partes: Viviendas, Personas y Migrantes. Para este trabajo, se utilizó la base de datos correspondientes a Personas ya que contiene la información necesaria para llevar a cabo el ajuste del modelo de ingresos propuesto en \ref{modelo_final}. El volumen de datos con el que se trabajó es amplio por lo que lo primero fue seleccionar las variables en la base de datos que representan a los regresores. Posteriormente, se agregaron los siguientes filtros:

\begin{enumerate}
    \item Se seleccionaron solamente las personas que tienen un trabajo remunerado. Es decir, no se consideró a las personas que
    se ocupan de las labores del hogar, son jubiladas o pensionadas, estudiantes o tienen alguna incapacidad que les impida tener un sueldo. 
    
    \item Se descartó a las personas que viven y trabajan fuera de la República Mexicana. 
    
    \item Se seleccionaron a las personas que especificaron horas trabajadas e ingreso ganado.
    
    \item Cada regresor es resultado de una pregunta hecha y tiene una variable asignada. Si el entrevistado decide no responder a alguna pregunta se marca la respuesta como \texttt{No especificado}. En este caso, se eliminaron a las personas que no respondieron alguna de las preguntas que corresponden a los regresores. 
\end{enumerate}

Con los filtros anteriores la cantidad de datos con la que se trabaja se reduce de 15 a 3.5 millones. Este proceso tomó alrededor de 20 minutos en ejecutarse y, posteriormente, se guardó la nueva base de datos. El filtrado de la información se ejecutó en \textsf{Julia} y se guardó para utilizarla posteriormente en \textsf{R} y \textsf{Python}. El código de lectura de la base de datos y los comandos utilizados para la selección de información son los siguientes. A pesar de ser un código largo, está debidamente documentado. 


\begin{minted}{julia}
	# Inicio de código para filtrado de datos
julia> using CSV, DataFrames, StatsBase, GLM, 
Random, CategoricalArrays

	# Equivalente a set.seed de R
Random.seed!(99)

	# Lectura la base de datos 
	# (toma alrededor de 4 minutos en cargar)
personas = CSV.read("Personas00.csv", DataFrame)

	# Lista con columnas necesarias para el ajuste
col_sel = ["ID_PERSONA", "SEXO", "EDAD", "NIVACAD", 
"ALFABET", "INGTRMEN","HORTRA", "SITTRA", 
"ENT_PAIS_TRAB", "AGUINALDO", "VACACIONES", 
"SERVICIO_MEDICO", "CONACT", "ENT"]
         
	# Se seleccionan de la base de datos 
personas_filt = personas[:, col_sel]    

	# FILTRO 1
julia> cond_act = [10, 13, 14, 15, 16, 17, 18, 19, 20]
personas_filt = subset(personas_filt, 
:CONACT => ByRow(in(cond_act)), skipmissing = true)

	# FILTRO 2
julia> personas_filt = subset(personas_filt, 
:ENT_PAIS_TRAB => ByRow(<(33)), skipmissing = true)

personas_filt = subset(personas_filt, 
:ENT => ByRow(<(33)), skipmissing = true)

	# FILTRO 3
julia> personas_filt = subset(personas_filt, :HORTRA => 
ByRow(!=(999)), skipmissing = true)

personas_filt = subset(personas_filt, :INGTRMEN => 
ByRow(!=(999999)), skipmissing = true)

	# FILTRO 4
function diferente_a(dataframe, columna, condicion)
	dataframe = subset(dataframe, columna => 
	ByRow(!=(condicion)), skipmissing = true)  
    return dataframe
end

julia> categorias_9 = ["SEXO", "AGUINALDO", "VACACIONES",
"SERVICIO_MEDICO", "ALFABET", "SITTRA"]

categorias_99 = ["NIVACAD"]

for i = 1:length(categorias_9)
    personas_filt = diferente_a(personas_filt, 
    categorias_9[i], 9)
end

for i = 1:length(categorias_99)
    personas_filt = diferente_a(personas_filt, 
    categorias_99[i], 99)
end

	# Finalmente, se guarda el nuevo dataframe
CSV.write("personas_filtradas.csv", personas_filt)
\end{minted}


\section{Factores y Sub-ajustes} \label{reg_categorias}

Lo primero que se debe verificar es que la lectura de datos haya clasificado las variables de manera correcta. En el modelo presentado en \ref{modelo_final}, la mayoría de las variables del ajuste son categorías o factores, pero \textsf{Julia} las lee como \textsf{Int64}. Por ejemplo, la variable \texttt{NIVACAD} responde a la pregunta sobre el último año o grado aprobado por el entrevistado. Hay 15 respuestas que corresponden a todos los niveles académicos posibles, desde no haber recibido ningún tipo de educación formal hasta haber obtenido un doctorado. Cada respuesta se identifica con un número que va del 0 al 14. Por lo tanto, en el modelo propuesto \ref{modelo_final}, el regresor \texttt{NIVACAD} es de tipo categórico y tiene 15 niveles. Ya que las respuestas son número, el comando \texttt{CSV.read} de \textsf{Julia} identifica incorrectamente la columna como tipo \textsf{Int64}. Esto sucede con todos los factores del modelo compilados en la lista \texttt{categorias} del código mostrado a continuación. En el siguiente código se muestra la manera en la que se convirtieron las variables a factores. 

\begin{minted}{julia}
julia> using DataFrames
data = CSV.read("personas_filtradas.csv", DataFrame)

	# Vector con todas las categorias
vector_categorias = ["SEXO", "AGUINALDO", "VACACIONES", 
"SERVICIO_MEDICO", "ALFABET", "NIVACAD", "ENT_PAIS_TRAB", 
"ENT", "SITTRA"]

transform!(data, names(data, vector_categorias) 
.=> categorical, renamecols=false)
\end{minted}

Si se omitiera el paso anterior el resultado del ajuste no tendría sentido ya que se considerarían a los regresores de tipo categórico como regresores continuos. Por tanto, no proporcionarían el efecto de cada categoría en la variable de respuesta.

Uno de los objetivos de este trabajo es ilustrar las capacidades de los tres lenguajes de programación por lo que se tomó el modelo \ref{modelo_final} y se retiraron algunas variables. Se puede pensar como que se tomaron diferentes subconjuntos de variables y, con ellas, se hizo el ajuste de las regresiones para notar si había cambios en la precisión del ajuste. La variable de respuesta es la misma en todos los ahora denominados \textit{sub-ajustes}.

El primer \textit{sub-ajuste} se definió con los primeros 5 regresores del modelo \ref{modelo_final} y se nombró como \textsf{fit5} (por la cantidad de regresores). Es decir, el modelo \textsf{fit5} es 

\begin{equation*}
    \begin{aligned}
 	y =& \beta_0 + \beta_1*horas_{trabajadas} + \beta_2*sexo + \\
    	&\beta_3*edad + \beta_4*escolaridad + \beta_5*entidad_{trabajo} 
    \end{aligned}
\end{equation*}


El segundo \textit{sub-ajuste} llamado \textsf{fit6} tiene los 5 regresores incluidos en \textsf{fit5} y uno extra, la posición laboral. Por tanto, el modelo \textsf{fit6} queda de la siguiente manera: 

\begin{equation*}
    \begin{aligned}
    	y =& \beta_0 + \beta_1*horas_{trabajadas} + \beta_2*sexo + \\
    	&\beta_3*edad + \beta_4*escolaridad + \beta_5*entidad_{trabajo} + \\
    	& \beta_6*posicion_{laboral}
    \end{aligned}
\end{equation*}

Los sub-ajustes \textsf{fit5} y \textsf{fit6} siguen el mismo orden que \ref{modelo_final}. Esto no es una coincidencia. El orden de los regresores del modelo \ref{modelo_final} está pensado precisamente para que cada variable sumada se agregue al conjunto de variables anterior y cree un nuevo modelo \textsf{fit}.

\subsection{Código en Julia}

Sería interesante ver la reacción de Galton si supiera los alcances a los que ha llegado su experimento de semillas. Él mismo estaría de acuerdo con que no es lo mismo hacer un ajuste con 5 observaciones a hacer uno con 5 millones de ellas. El código es el mismo, pero en el trabajo de máquina se observan cambios en tiempo de ejecución y precisión numérica. Ambos factores son las razones por las que se eligió este ejercicio. En esta sección se muestra como se midieron dichos cambios.

Cada uno de los modelos \textsf{fit} ya mencionados se ejecutaron con muestras de 500, 5 mil, 50 mil, 500 mil y 2.5 millones de observaciones. Es decir, se usaron cada una de las expresiones \textsf{fit} para el ajuste de modelos con los volúmenes de información antes mencionados. La elección de observaciones se hizo al azar usando el comando \texttt{sample} en \textsf{Julia}. Una vez seleccionadas, se guardaba el dataframe generado para usar exactamente los mismos datos en \textsf{R} y \textsf{Python}. Guardar las muestras generadas tiene el propósito de poder utilizar la misma información en los ajustes y obtener así, un punto de comparación en la precisión del cálculo de los coeficientes. 

La ejecución de lo anterior es repetitivo por lo que se buscó fuera hecho de la manera más rápida y eficiente posible. Se desarrolló una función para cada \textsf{fit} cuyos argumentos fueran la cantidad de observaciones que se utilizan y el nombre con el que se guarda el archivo. El nombre de las funciones coinciden con la cantidad de regresores que se están utilizando. 

Inclusive con este acercamiento, se puede notar que crear una función para cada modelo resulta repetitivo. Se pudo haber desarrollado una sola función que también tomara como argumento la fórmula a utilizarse en el ajuste. Sin embargo, se decidió no hacerlo de esa forma ya que se consideró de suma importancia tener la fórmula escrita en cada función. 

Debido a la similitud entre funciones y su ejecución se muestran solamente las correspondientes a \textsf{fit5} y \textsf{fit10} a manera de ejemplo. El código para la función \textsf{fit5} es el siguiente.

\begin{minted}{julia}
	# FIT BASE
julia> function fit5(cantidad_sample, nombre_facil)
	nombre_fit = "fit5"
	
	sample_rows = sample(1:nrow(data), cantidad_sample, 
		replace=false)
	
	df_sample = data[sample_rows, :]
	
	nombre_completo = nombre_facil*"_"*nombre_fit*".csv"
	# Guardamos el documentos para usarlo en R
	CSV.write(nombre_completo, df_sample)
	
	tiempos = []
	local sample_fit
	# Hacemos el fit
	for i in runs
		sample_fit = @timed 
		lm(@formula(INGTRMEN ~ HORTRA 
		+ SEXO + EDAD + NIVACAD + ENT_PAIS_TRAB), 
		df_sample)
		push!(tiempos, sample_fit[2])
	end
	
	aux = "res_"
	nombre_completo = aux*nombre_completo
	CSV.write(nombre_completo, coeftable(sample_fit[1]))
	return tiempos
end 

# Fit 5
julia> tiempos_fit5 = DataFrame()
julia> tiempos_fit5[!, "500"] = fit5(500, "500")
julia> tiempos_fit5[!, "5mil"] = fit5(5000, "5mil")
julia> tiempos_fit5[!, "50mil"] = fit5(50000, "50mil")
julia> tiempos_fit5[!, "500mil"] = fit5(500000, "500mil")
julia> tiempos_fit5[!, "2500mil"] = fit5(2500000, "2500mil")
julia> CSV.write("tiemposJulia_Censo_fit5.csv", tiempos_fit5)

\end{minted}

Por otro lado, el código para \textsf{fit10} es el siguiente. 

\begin{minted}{julia}
	# FIT 10
julia> function fit10(cantidad_sample, nombre_facil)
	nombre_fit = "fit10"

	sample_rows = sample(1:nrow(data), cantidad_sample, 
	replace=false)

	df_sample = data[sample_rows, :]

	nombre_completo = nombre_facil*"_"*nombre_fit*".csv"
# Guardamos el documentos para usarlo en R
	CSV.write(nombre_completo, df_sample)

	tiempos = []
	local sample_fit
# Hacemos el fit
	for i in runs
	  sample_fit = @timed lm(@formula(INGTRMEN ~ HORTRA 
	  + SEXO + EDAD + NIVACAD + ENT_PAIS_TRAB + SITTRA 
	  + ALFABET + AGUINALDO + VACACIONES 
	  + SERVICIO_MEDICO), df_sample)   
	  push!(tiempos, sample_fit[2])
	end  

	aux = "res_"
	nombre_completo = aux*nombre_completo
	CSV.write(nombre_completo, coeftable(sample_fit[1]))
	return tiempos
end 

# # # Fit 10: Fit 5 + SITTRA + ALFABET + AGUINALDO + 
# # # VACACIONES + SERVICIO_MEDICO
julia> tiempos_fit = DataFrame()
julia> tiempos_fit[!, "500"] = fit10(500, "500")
julia> tiempos_fit[!, "5mil"] = fit10(5000, "5mil")
julia> tiempos_fit[!, "50mil"] = fit10(50000, "50mil")
julia> tiempos_fit[!, "500mil"] = fit10(500000, "500mil")
julia> tiempos_fit[!, "2500mil"] = fit10(2500000, "2500mil")
julia> CSV.write("tiemposJulia_Censo_fit10.csv", tiempos_fit)

\end{minted}

\section{Resultados y Conclusiones}

En cualquiera de los sub-ajustes, la mayoría de los regresores son de tipo categórico por lo cual tiene diferentes niveles. La variable \textsf{NIVACAD} comentada en la sección anterior es un ejemplo de ello. Otro ejemplo es la variable llamada \textsf{ENT\_PAIS\_TRAB} que corresponde a la entidad mexicana donde el entrevistado trabajó más recientemente. Ya que México se divide en 32 entidades federativas, cada estado representa un nivel del regresor.  Si se cuentan los niveles de cada factor, al final el modelo con más variables, \textsf{fit10}, tiene un total de 54 regresores. La tabla \ref{res_fit10_2500mil} es una muestra resumida de los resultados obtenidos en \textsf{Julia} usando 2.5 millones de observaciones en el modelo \textsf{fit10}.  


\begin{center}
	\resizebox{\textwidth}{!}{%
		\begin{tabular}{|Scccccc|} 
			\hline
			Nombre & \multicolumn{1}{V}{Coeficiente} & \multicolumn{1}{M}{Error estándar}  & \multicolumn{1}{M}{$t$} & $Pr(>|t|$) & \multicolumn{1}{M}{95\% inf}  & \multicolumn{1}{M|}{95\% sup} \\ 
			\hline 
			Ordenada al origen & 4133.26 & 125.42 & 32.95 & $4.16e^{-238}$ & 3887.43 & 4379.09\\ 
			
			SEXO:3 & -1407.49 & 20.27 & -69.42 & 0 & -1447.23 & -1367.76 \\ 
			
			EDAD & 33.30 & 0.72 & 46.12 & 0 & 31.88 & 34.71 \\ 
			
			NIVACAD:1 & 208.16 & 209.00 & 0.99 & 0.32 & -201.48 & 617.80 \\
			
			NIVACAD:2 & 287.16 & 68.59 & 4.18 & $2.38e^{-05}$ & 152.72 & 421.60 \\
			
			NIVACAD:3 & 629.53 & 71.20 & 8.84 & $9.42e^{-19}$ & 489.98 & 769.08 \\
			
			\vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots \\
			
			SITTRA:3 & -692.44 & 32.10 & -21.57 & $3.30e^{-103}$ & -755.35 & -629.53 \\
			
			ALFABET:3 & -544.43 & 66.47 & -8.19 & $2.59e^{-16}$ & -674.70 & -414.16 \\
			
			AGUINALDO:2 & -459.48 & 34.30 & -13.39 & $6.51e^{-41}$ & -526.71 & -392.25 \\
			
			VACACIONES:4 & -843.60 & 38.65 & -21.83 & $1.31e^{-105}$ & -919.35 & 7678.85 \\
			
			SERVICIO \_MEDICO:6 & -1110.25 & 34.21 & -32.46 & $4.91e^{-231}$ & -1177.30 & -1043.21 \\
			
			\hline
	\end{tabular}} 
	\captionof{table}{Resultados para el modelo fit10 con 2.5 millones de observaciones en Julia} \label{res_fit10_2500mil}
\end{center}


Como se observa en la tabla \ref{res_fit10_2500mil}, \textsf{Julia} no solo da el cálculo de los coeficientes, también da indicadores como lo son el error estándar y el intervalo de confianza. 

En \textsf{R} se utilizó la función \texttt{lm} para hacer los ajustes mientras que en \textsf{Python} se usó la función \texttt{LinearRegression()} del paquete \texttt{sklearn} explicado a detalle en la sección \ref{sec_sklearn}. El código completo en ambos lenguajes se encuentra en el apéndice \ref{apendice_censo}. 

Los tres lenguajes hacen el ajuste de manera correcta y con el mismo nivel de precisión. Se notó que, para cada \textit{sub-ajuste}, los tres volúmenes de información más pequeños obtenían un resultado de ajuste muy distinto. Sin embargo, para los ajustes donde se utilizaron 500 mil y 2.5 millones de observaciones el cálculo de coeficientes era muy similar. En la tabla \ref{comparacion_precision} se presenta una comparativa de los resultados obtenidos en los tres lenguajes usando el \textit{sub-ajuste} \textsf{fit10} con 2.5 millones de datos. A manera de ejemplo, se seleccionaron todos los regresores continuos y un nivel de cada regresor categórico. Asimismo, en la tabla se omitió redondear los resultados del ajuste para observar el nivel de precisión. En este caso, la precisión numérica se mantuvo igual en los tres lenguajes. 

\begin{center}
	\begin{tabular}{|c|c|c|c|} 
		\hline
		Regresor & Julia & R  & Python  \\ 
		\hline 
		Ordenada al origen & 4044.00297 & 4044.00297 & 4044.00297 \\ 
		
		HORTRA & 41.12933 & 41.12933 & 41.12933 \\
		
		SEXO:3 & -1403.30415 & -1403.30415 & -1403.30415 \\ 
		
		EDAD & 34.34650 & 34.34650 & 34.34650 \\ 
		
		NIVACAD:9 & 4276.80672 & 4276.80672 & 4276.80672 \\
		
		ENT\_PAIS\_TRAB:13 & -671.72888 & -671.72888 & -671.72888 \\
		
		SITTRA:2 & -668.43938 & -668.43938 & -668.43938 \\
		
		ALFABET:3 & -534.68337 & -534.68337 & -534.68337 \\
		
		AGUINALDO:2 & -483.42688 & -483.42688 & -483.42688 \\
		
		VACACIONES:4 & -812.44030 & -812.44030 & -812.44030 \\
		
		SERVICIO\_MEDICO: 6 & -1118.54895 & -1118.54895 & -1118.54895 \\
		
		\hline
	\end{tabular} 
	\captionof{table}{Comparación de resultados para el modelo fit10 con 2.5 millones de observaciones en R, Julia y Python} \label{comparacion_precision}
\end{center}

Por otro lado, en cuanto a tiempo de ejecución, la tabla \ref{app_censo_tiempos} muestra el tiempo que le tomo a los tres lenguajes ejecutar cada ajuste. Los tres lenguajes presentan un aumento de tiempo a medida que aumenta el volumen de observaciones a ajustar. Asimismo, se presenta un aumento menos significativo en los tiempos de ejecución a medida que aumenta el número de regresores. \textsf{Julia} y \textsf{Python} presentan tiempos de ejecución muy similares en todos los ajustes donde se utilizaron 500 mil datos o menos. \textsf{Python} mantiene su rapidez cuando se utilizan 2.5 millones de datos, mientras que \textsf{Julia} presenta un aumento en tiempos de ejecución a medida que aumentan la cantidad de regresores utilizados para el ajuste. 

La diferencia en tiempo se hace más notoria si se considera la ejecución del código completo. El desempeño de \textsf{Julia} parece ser más lento en general ya que invierte una cantidad considerable de tiempo en guardar los resultados en un archivo de tipo \textsf{CSV}. Por otro lado, el tiempo de ejecución del código completo en \textsf{Python} es menor. Por lo tanto, la experiencia de usuario, en general, es que a \textsf{Python} le toma menos tiempo obtener los resultados de la regresión. 

En cambio, \textsf{R} es el lenguaje más lento de la triada de lenguajes. Su tiempo mínimo de ejecución es de 25.170 segundos mientras que el tiempo máximo es de 42.471 segundos. Adicionalmente, el lenguaje presenta dificultades al manejar grandes cantidades de datos. Se presentó una sensación de entorpecimiento en la ejecución del código ya que los cálculos eran lentos y, en ocasiones, se presentó un mensaje que pedía reiniciar la sesión de \textsf{R}.   

En suma, en este ejemplo el paquete \texttt{GLM} de \textsf{Julia} cumple su propósito de ajustar el modelo de manera correcta y rápida. Más aún, el paquete también proporciona los estimadores necesarios para un análisis completo de regresión. En cambio, si bien las funciones utilizadas en \textsf{R} y \textsf{Python} no presentan dicha tabla, sí existen los comandos para obtener los estimadores. 

Los tres lenguajes \textsf{Julia, R} y \textsf{Python} proporcionan herramientas que permiten leer una base de datos y ajustar un modelo lineal de manera precisa. Además, los lenguajes ofrecen herramientas para calcular los estimadores clave para hacer un análisis de regresión. Las diferencias entre los lenguajes se presentan al considerar el tiempo de ejecución y el rendimiento. \textsf{Julia} y \textsf{Python} realizan el ajuste de manera rápida y fluida, sin saturaciones de memoria o falta de respuesta del lenguaje. En cambio, \textsf{R} presenta complicaciones en el manejo de bases de datos extensas. En consecuencia, es el lenguaje más lento en realizar el ajuste y pide el constante reinicio de la sesión en la que se está trabajando. 

Los obstáculos presentados con \textsf{R} dieron pie a la realización de que, hasta este punto, la ejecución de \textsf{Julia} nunca ha presentado fallas. Investigando sobre las capacidades de \textsf{Julia} se encontró en repetidas ocasiones que tiene un propósito muy claro: ser  el lenguaje más eficiente con la mayor cantidad de aplicaciones posible. Por lo tanto, en el siguiente capítulo se cambia el enfoque de análisis de regresión para ilustrar un ejemplo de discriminación de modelos en diseños de experimentos. El objetivo del problema es mostrar la capacidad de los lenguajes de ejecutar una función que conlleva una gran cantidad de cálculos complejos. 

